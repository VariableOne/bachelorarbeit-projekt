{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb6abdb9",
   "metadata": {},
   "source": [
    "# Ein Hybridmodell mit LSTM-AE, DBSCAN und IF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8183868f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-09 12:18:33.714542: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1754734713.736124  296125 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1754734713.742640  296125 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1754734713.759674  296125 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754734713.759699  296125 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754734713.759701  296125 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754734713.759704  296125 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-09 12:18:33.766098: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "import logging\n",
    "from tensorflow.keras.layers import TimeDistributed, Dense, LSTM, Dropout, LayerNormalization, Input, Add, Bidirectional, RepeatVector\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "import sys\n",
    "from keras.layers import LSTM, Dropout, LayerNormalization, Add, TimeDistributed, Dense\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve, average_precision_score\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b37113",
   "metadata": {},
   "source": [
    "## 1. Vorbereitung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6d26b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Quadro K1100M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ueay/bachelorarbeit-projekt/env/lib/python3.12/site-packages/torch/cuda/__init__.py:262: UserWarning: \n",
      "    Found GPU0 Quadro K1100M which is of cuda capability 3.0.\n",
      "    PyTorch no longer supports this GPU because it is too old.\n",
      "    The minimum cuda capability supported by this library is 3.7.\n",
      "    \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e44ba590",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2df9da31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dotenv import load_dotenv\n",
    "# import requests\n",
    "# import os\n",
    "\n",
    "# event_url = os.environ.get(\"EVENT_URL\")\n",
    "\n",
    "# def get_all_events(token):\n",
    "#     headers = {'Authorization': f'Bearer {token}'}\n",
    "#     all_events = []\n",
    "#     params = {'max': 5000}\n",
    "#     resp = requests.get(event_url, headers=headers, params=params)\n",
    "#     resp.raise_for_status()\n",
    "#     batch = resp.json()\n",
    "#     all_events.extend(batch)\n",
    "\n",
    "#     return all_events\n",
    "\n",
    "# server_url = os.environ.get(\"URL\")\n",
    "# client_id = os.environ.get(\"CLIENT_ID\")\n",
    "# client_secret = os.environ.get(\"CLIENT_SECRET\")\n",
    "# token_url = os.environ.get(\"TOKEN_URL\")\n",
    "# keycloak_url = os.environ.get(\"keycloak_url\")\n",
    "# authRealm = os.environ.get(\"authRealm\")\n",
    "# realm = os.environ.get(\"realm\")\n",
    "\n",
    "# load_dotenv()\n",
    "\n",
    "# def get_token():\n",
    "#     data = {\n",
    "#         'keycloak_url': keycloak_url,\n",
    "#         'authRealm': authRealm,\n",
    "#         'realm': realm,\n",
    "#         'client_id': client_id,\n",
    "#         'client_secret': client_secret,\n",
    "#         'grant_type': 'client_credentials'\n",
    "#         }\n",
    "#     resp = requests.post(token_url, data=data)\n",
    "#     resp.raise_for_status()\n",
    "#     token = resp.json()['access_token']\n",
    "#     return token\n",
    "\n",
    "# token = get_token()\n",
    "# events = get_all_events(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6234ad6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime\n",
    "# import json\n",
    "\n",
    "\n",
    "# filename = datetime.now().strftime(\"keycloak_events_%Y-%m-%d.jsonl\")\n",
    "# with open(filename, \"a\") as f:\n",
    "#     for event in events:\n",
    "#         f.write(json.dumps(event) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185398f1",
   "metadata": {},
   "source": [
    "#### Daten laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb5a6c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_json(\"train-data.jsonl\", lines=True)\n",
    "data_test = pd.read_json(\"test-data.jsonl\", lines=True)\n",
    "data_val = pd.read_json(\"val-data.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "321cb5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full = pd.DataFrame(data_train)\n",
    "X_test_full = pd.DataFrame(data_test)\n",
    "X_val_full = pd.DataFrame(data_val)\n",
    "\n",
    "# data_test['label'] = data_test['details'].apply(lambda x: x.get('label', None))\n",
    "# data_val['label'] = data_val['details'].apply(lambda x: x.get('label', None))\n",
    "y_test_full = data_test[\"label\"]\n",
    "y_val_full = data_val[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b904244",
   "metadata": {},
   "source": [
    "#### Automatisch alles in Numerische oder Kategorische Daten einteilen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aeaa7cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "def is_missing(val):\n",
    "    return val is None or (isinstance(val, float) and np.isnan(val))\n",
    "\n",
    "def flatten_log_entry(log, parent_key='', sep='.'):\n",
    "    items = []\n",
    "    for k, v in log.items():\n",
    "        new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
    "        if isinstance(v, dict):\n",
    "            items.extend(flatten_log_entry(v, new_key, sep=sep).items())\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)\n",
    "\n",
    "def auto_encode_features(logs, one_hot_numeric=False, label_encoders=None, onehot_encoders=None, fit=True):\n",
    "    # Logs flach machen\n",
    "    flat_logs = [flatten_log_entry(log) for log in logs]\n",
    "\n",
    "    if label_encoders is None:\n",
    "        label_encoders = {}\n",
    "    if onehot_encoders is None:\n",
    "        onehot_encoders = {}\n",
    "\n",
    "    # Encoder vorbereiten\n",
    "    for key in flat_logs[0].keys():\n",
    "        values = []\n",
    "        for log in flat_logs:\n",
    "            val = log.get(key)\n",
    "\n",
    "            if is_missing(val):\n",
    "                val = \"__MISSING__\"\n",
    "            elif isinstance(val, (list, dict)):\n",
    "                print(f\"Feature '{key}' enthält nicht-skalaren Wert – wird als String gespeichert: {val}\")\n",
    "                val = str(val)\n",
    "\n",
    "            values.append(val)\n",
    "\n",
    "        if fit:\n",
    "            try:\n",
    "                le = LabelEncoder()\n",
    "                le.fit(values)\n",
    "                label_encoders[key] = le\n",
    "            except Exception as e:\n",
    "                print(f\"Fehler beim Enkodieren von Feature '{key}': {e}\")\n",
    "                continue\n",
    "\n",
    "    # Feature-Werte transformieren\n",
    "    encoded_logs = []\n",
    "    for log in flat_logs:\n",
    "        encoded_log = {}\n",
    "        for key, le in label_encoders.items():\n",
    "            val = log.get(key, \"__MISSING__\")\n",
    "            if is_missing(val):\n",
    "                val = \"__MISSING__\"\n",
    "            elif isinstance(val, (list, dict)):\n",
    "                val = str(val)\n",
    "            try:\n",
    "                encoded_log[key] = le.transform([val])[0]\n",
    "            except ValueError:\n",
    "                encoded_log[key] = -1  # unbekannte Kategorie\n",
    "        encoded_logs.append(encoded_log)\n",
    "\n",
    "    return encoded_logs, label_encoders, onehot_encoders\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3ff107",
   "metadata": {},
   "source": [
    "#### Werte aus vorheriger Funktion vereinigen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4d0002f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dicts_to_feature_matrix(encoded_logs):\n",
    "    feature_names = sorted({key for d in encoded_logs for key in d.keys()})\n",
    "\n",
    "    X = np.zeros((len(encoded_logs), len(feature_names)), dtype=np.float32)\n",
    "\n",
    "    for i, d in enumerate(encoded_logs):\n",
    "        for j, feat in enumerate(feature_names):\n",
    "            if feat in d:\n",
    "                X[i, j] = d[feat]\n",
    "\n",
    "    return X, feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d825cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_train = X_train_full.to_dict(orient='records')\n",
    "#logs_train = events\n",
    "logs_test = X_test_full.to_dict(orient='records')\n",
    "logs_val = X_val_full.to_dict(orient='records')\n",
    "\n",
    "encoded_logs, label_encoders, onehot_encoders = auto_encode_features(\n",
    "    logs_train, one_hot_numeric=False, fit=True\n",
    ")\n",
    "X_train, feature_names = dicts_to_feature_matrix(encoded_logs)\n",
    "\n",
    "encoded_test_logs, _, _ = auto_encode_features(\n",
    "    logs_test, one_hot_numeric=False,\n",
    "    label_encoders=label_encoders, onehot_encoders=onehot_encoders, fit=False\n",
    ")\n",
    "X_test, _ = dicts_to_feature_matrix(encoded_test_logs)\n",
    "\n",
    "encoded_val_logs, _, _ = auto_encode_features(\n",
    "    logs_val, one_hot_numeric=False,\n",
    "    label_encoders=label_encoders, onehot_encoders=onehot_encoders, fit=False\n",
    ")\n",
    "X_val, _ = dicts_to_feature_matrix(encoded_val_logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b55383",
   "metadata": {},
   "source": [
    "#### Skalierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3445ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_val_scaled = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f955d4",
   "metadata": {},
   "source": [
    "### Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad52d0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 10\n",
    "batch_size = 10       \n",
    "\n",
    "encoder_layers = [256, 128, 64, 32, 16, 8, 4, 2]\n",
    "decoder_layers = [2, 4, 8, 16, 32, 64, 128, 256]\n",
    "\n",
    "dropout_rate = 0.0\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31049ba2",
   "metadata": {},
   "source": [
    "### Sequenzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b87923e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceToSequenceGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, data, seq_length, batch_size, pad_last=True):\n",
    "        self.data = data\n",
    "        self.seq_length = seq_length\n",
    "        self.batch_size = batch_size\n",
    "        self.pad_last = pad_last\n",
    "\n",
    "        self.indices = np.arange(len(data) - seq_length)\n",
    "        \n",
    "        # Wenn Padding aktiv ist und etwas übrig bleibt\n",
    "        if pad_last and (len(data) % seq_length != 0):\n",
    "            self.include_last = True\n",
    "        else:\n",
    "            self.include_last = False\n",
    "\n",
    "    def __len__(self):\n",
    "        base = (len(self.indices) + self.batch_size - 1) // self.batch_size\n",
    "        return base + (1 if self.include_last else 0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx < len(self) - 1 or not self.include_last:\n",
    "            batch_idx = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "            X_batch = np.array([self.data[i:i + self.seq_length] for i in batch_idx])\n",
    "        else:\n",
    "            # letzte Sequenz mit Padding\n",
    "            last_seq = self.data[-self.seq_length:]\n",
    "            if len(last_seq) < self.seq_length:\n",
    "                padding_len = self.seq_length - len(last_seq)\n",
    "                padding = np.zeros((padding_len, self.data.shape[1]))\n",
    "                last_seq = np.vstack((last_seq, padding))\n",
    "            X_batch = np.expand_dims(last_seq, axis=0)\n",
    "\n",
    "        return X_batch, X_batch\n",
    "\n",
    "train_gen = SequenceToSequenceGenerator(X_train_scaled, seq_length, batch_size)\n",
    "val_gen = SequenceToSequenceGenerator(X_val_scaled, seq_length, batch_size)\n",
    "test_gen = SequenceToSequenceGenerator(X_test_scaled, seq_length, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33d7452",
   "metadata": {},
   "source": [
    "## 2. LSTM-AE implementieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8edbf86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1754736060.758925  296125 gpu_device.cc:2383] Ignoring visible gpu device (device: 0, name: Quadro K1100M, pci bus id: 0000:01:00.0, compute capability: 3.0) with Cuda compute capability 3.0. The minimum required Cuda capability is 3.5.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">559,104</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">656,384</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">164,352</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">41,216</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,368</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">672</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ repeat_vector (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_10                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_11                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,088</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_12                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_13                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_14                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_15                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_16                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,208</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │       \u001b[38;5;34m559,104\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │       \u001b[38;5;34m656,384\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │       \u001b[38;5;34m164,352\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m41,216\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_4 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │        \u001b[38;5;34m10,368\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_5 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │         \u001b[38;5;34m2,624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_6 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m8\u001b[0m)          │           \u001b[38;5;34m672\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m8\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_7 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m4\u001b[0m)          │           \u001b[38;5;34m176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m4\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_8 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m112\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ repeat_vector (\u001b[38;5;33mRepeatVector\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m4\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_9 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m4\u001b[0m)          │           \u001b[38;5;34m112\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m4\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_10                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m8\u001b[0m)          │           \u001b[38;5;34m288\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m8\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_11                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │         \u001b[38;5;34m1,088\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_12                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │         \u001b[38;5;34m4,224\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_13                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m16,640\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_14                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m66,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_15                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │       \u001b[38;5;34m263,168\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_14 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_16                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │     \u001b[38;5;34m1,050,624\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_15 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │         \u001b[38;5;34m8,208\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,845,408</span> (10.85 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,845,408\u001b[0m (10.85 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,845,408</span> (10.85 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,845,408\u001b[0m (10.85 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Bidirectional, LSTM, RepeatVector, TimeDistributed, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "n_features = X_train_scaled.shape[1]\n",
    "\n",
    "inputs = Input(shape=(seq_length, n_features))\n",
    "x = inputs\n",
    "\n",
    "# Tieferer Encoder mit bidirektionalen LSTMs\n",
    "for units in encoder_layers:\n",
    "    x = Bidirectional(LSTM(units, return_sequences=True))(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "\n",
    "# Letzte Encoder-Schicht ohne return_sequences, nur den letzten Output\n",
    "encoded = Bidirectional(LSTM(encoder_layers[-1]))(x)\n",
    "\n",
    "# Tieferer Decoder\n",
    "x = RepeatVector(seq_length)(encoded)\n",
    "for units in decoder_layers:\n",
    "    x = Bidirectional(LSTM(units, return_sequences=True))(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "\n",
    "outputs = TimeDistributed(Dense(n_features, activation='linear'))(x)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "model.compile(optimizer=Adam(learning_rate), loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b747efe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ueay/bachelorarbeit-projekt/env/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m410s\u001b[0m 134ms/step - loss: 0.7632\n",
      "Epoch 2/50\n",
      "\u001b[1m   1/2799\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:45\u001b[0m 188ms/step - loss: 0.3390"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ueay/bachelorarbeit-projekt/env/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:153: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "  current = self.get_monitor_value(logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m387s\u001b[0m 138ms/step - loss: 0.6085\n",
      "Epoch 3/50\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m385s\u001b[0m 138ms/step - loss: 0.6363\n",
      "Epoch 4/50\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m403s\u001b[0m 144ms/step - loss: 0.6066\n",
      "Epoch 5/50\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m390s\u001b[0m 139ms/step - loss: 0.5625\n",
      "Epoch 6/50\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m375s\u001b[0m 134ms/step - loss: 0.6689\n",
      "Epoch 7/50\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m344s\u001b[0m 123ms/step - loss: 0.6091\n",
      "Epoch 8/50\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m342s\u001b[0m 122ms/step - loss: 0.5819\n",
      "Epoch 9/50\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m345s\u001b[0m 123ms/step - loss: 0.5991\n",
      "Epoch 10/50\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m344s\u001b[0m 123ms/step - loss: 0.6826\n",
      "Epoch 11/50\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m344s\u001b[0m 123ms/step - loss: 0.4931\n",
      "Epoch 12/50\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m343s\u001b[0m 122ms/step - loss: 0.6230\n",
      "Epoch 13/50\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m348s\u001b[0m 124ms/step - loss: 0.5827\n",
      "Epoch 14/50\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m344s\u001b[0m 123ms/step - loss: 0.5429\n",
      "Epoch 15/50\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m344s\u001b[0m 123ms/step - loss: 0.5184\n",
      "Epoch 16/50\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m345s\u001b[0m 123ms/step - loss: 0.7032\n",
      "Epoch 17/50\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m350s\u001b[0m 125ms/step - loss: 0.6133\n",
      "Epoch 18/50\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m347s\u001b[0m 124ms/step - loss: 0.7477\n",
      "Epoch 19/50\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m349s\u001b[0m 125ms/step - loss: 0.6953\n",
      "Epoch 20/50\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m351s\u001b[0m 125ms/step - loss: 0.5673\n",
      "Epoch 21/50\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m350s\u001b[0m 125ms/step - loss: 0.5852\n",
      "Epoch 22/50\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m351s\u001b[0m 125ms/step - loss: 0.5709\n",
      "Epoch 23/50\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m351s\u001b[0m 125ms/step - loss: 0.5329\n",
      "Epoch 24/50\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m349s\u001b[0m 125ms/step - loss: 0.5672\n",
      "Epoch 25/50\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m351s\u001b[0m 125ms/step - loss: 0.5326\n",
      "Epoch 26/50\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m362s\u001b[0m 129ms/step - loss: 0.6249\n",
      "Epoch 27/50\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m430s\u001b[0m 154ms/step - loss: 0.5265\n",
      "Epoch 28/50\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m451s\u001b[0m 161ms/step - loss: 0.5817\n",
      "Epoch 29/50\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 145ms/step - loss: 0.5078\n",
      "Epoch 30/50\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m429s\u001b[0m 153ms/step - loss: 0.6112\n",
      "Epoch 31/50\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m379s\u001b[0m 135ms/step - loss: 0.5655\n",
      "Epoch 32/50\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m397s\u001b[0m 141ms/step - loss: 0.6355\n",
      "Epoch 33/50\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m410s\u001b[0m 146ms/step - loss: 0.5920\n",
      "Epoch 34/50\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m447s\u001b[0m 160ms/step - loss: 0.5549\n",
      "Epoch 35/50\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m405s\u001b[0m 145ms/step - loss: 0.5750\n",
      "Epoch 36/50\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m398s\u001b[0m 142ms/step - loss: 0.6582\n",
      "Epoch 37/50\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m375s\u001b[0m 134ms/step - loss: 0.5333\n",
      "Epoch 38/50\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m358s\u001b[0m 128ms/step - loss: 0.5157\n",
      "Epoch 39/50\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m356s\u001b[0m 127ms/step - loss: 0.6968\n",
      "Epoch 40/50\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m364s\u001b[0m 130ms/step - loss: 0.6807\n",
      "Epoch 41/50\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m367s\u001b[0m 131ms/step - loss: 0.6084\n",
      "Epoch 42/50\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m368s\u001b[0m 132ms/step - loss: 0.6562\n",
      "Epoch 43/50\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 133ms/step - loss: 0.6050\n",
      "Epoch 44/50\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 133ms/step - loss: 0.5444\n",
      "Epoch 45/50\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 134ms/step - loss: 0.6754\n",
      "Epoch 46/50\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m375s\u001b[0m 134ms/step - loss: 0.5537\n",
      "Epoch 47/50\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m375s\u001b[0m 134ms/step - loss: 0.5595\n",
      "Epoch 48/50\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m377s\u001b[0m 135ms/step - loss: 0.5267\n",
      "Epoch 49/50\n",
      "\u001b[1m2799/2799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m377s\u001b[0m 135ms/step - loss: 0.5436\n",
      "Epoch 50/50\n",
      "\u001b[1m 761/2799\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:02\u001b[0m 149ms/step - loss: 0.6568"
     ]
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "model.fit(train_gen, epochs=50, callbacks=[early_stop])#, validation_data=val_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5ebaae",
   "metadata": {},
   "source": [
    "### Umwandlung der Daten für nächste Modelle: Rekonstruktionsfehler berechnen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ede0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reconstruction_errors(gen, model):\n",
    "    errors = []\n",
    "    for i in range(len(gen)):\n",
    "        X_batch, _ = gen[i]\n",
    "        pred = model.predict(X_batch, verbose=0)\n",
    "        batch_errors = np.mean(np.square(X_batch - pred), axis=(1, 2))\n",
    "        errors.extend(batch_errors)\n",
    "    return np.array(errors)\n",
    "\n",
    "train_errors = get_reconstruction_errors(train_gen, model)\n",
    "val_errors = get_reconstruction_errors(val_gen, model)\n",
    "test_errors = get_reconstruction_errors(test_gen, model)\n",
    "\n",
    "reconstruction_errors = get_reconstruction_errors(test_gen, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00451659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wahre Labels passend zu reconstruction_errors extrahieren\n",
    "y_test_seq = np.array([y_test_full[i + seq_length - 1] for i in range(len(reconstruction_errors))])\n",
    "true_labels = y_test_seq.astype(int)\n",
    "\n",
    "# Sortiere die Fehler und berechne Lücken\n",
    "sorted_errors = np.sort(reconstruction_errors)\n",
    "gaps = np.diff(sorted_errors)\n",
    "\n",
    "# Index der größten Lücke finden\n",
    "max_gap_idx = np.argmax(gaps)\n",
    "# Schwellenwert als Mitte der größten Lücke\n",
    "optimal_threshold = (sorted_errors[max_gap_idx] + sorted_errors[max_gap_idx + 1]) / 2\n",
    "\n",
    "# Vorhersage basierend auf diesem Threshold\n",
    "y_pred = (reconstruction_errors > optimal_threshold).astype(int)\n",
    "\n",
    "# Metriken berechnen\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(true_labels, y_pred, average='binary')\n",
    "roc_auc = roc_auc_score(true_labels, reconstruction_errors)\n",
    "\n",
    "print(f\"Threshold (Gap-basierend): {optimal_threshold:.5f}\")\n",
    "print(f\"Precision: {precision:.3f}, Recall: {recall:.3f}, F1-Score: {f1:.3f}, ROC-AUC: {roc_auc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7452d490",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_rec = StandardScaler()\n",
    "scaler_rec.fit(train_errors.reshape(-1, 1))\n",
    "val_errors_scaled = scaler_rec.transform(val_errors.reshape(-1, 1))\n",
    "test_errors_scaled = scaler_rec.transform(test_errors.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8d600b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 4))\n",
    "plt.plot(reconstruction_errors, label=\"Rekonstruktionsfehler\", color=\"blue\")\n",
    "\n",
    "plt.scatter(\n",
    "    np.where(true_labels == 1)[0],\n",
    "    reconstruction_errors[true_labels == 1],\n",
    "    color=\"red\", label=\"Tatsächliche Anomalien\", marker=\"x\"\n",
    ")\n",
    "\n",
    "false_positives = (y_pred == 1) & (true_labels == 0)\n",
    "plt.scatter(\n",
    "    np.where(false_positives)[0],\n",
    "    reconstruction_errors[false_positives],\n",
    "    color=\"orange\", label=\"False Positives\", marker=\"o\", edgecolors='k'\n",
    ")\n",
    "\n",
    "false_negatives = (y_pred == 0) & (true_labels == 1)\n",
    "plt.scatter(\n",
    "    np.where(false_negatives)[0],\n",
    "    reconstruction_errors[false_negatives],\n",
    "    color=\"purple\", label=\"False Negatives\", marker=\"s\"\n",
    ")\n",
    "\n",
    "plt.axhline(optimal_threshold, color='gray', linestyle='--', label=\"Threshold\")\n",
    "plt.legend()\n",
    "plt.title(\"Rekonstruktionsfehler mit Fehlklassifikationen\")\n",
    "plt.xlabel(\"Zeitschritt / Index\")\n",
    "plt.ylabel(\"Fehler\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1734c09",
   "metadata": {},
   "source": [
    "# Modell 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2c9f11",
   "metadata": {},
   "source": [
    "## Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c7b6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "iforest = IsolationForest()\n",
    "iforest.fit(train_errors.reshape(-1, 1))\n",
    "\n",
    "test_preds_if = iforest.predict(test_errors.reshape(-1, 1))\n",
    "val_anomaly_if = (test_preds_if == -1).astype(int)\n",
    "\n",
    "y_test_seq_if = np.array([y_test_full[i + seq_length- 1] for i in range(len(val_anomaly_if))])\n",
    "true_labels_if = y_test_seq_if.astype(int)\n",
    "\n",
    "report_iforest_if = classification_report(true_labels_if, val_anomaly_if)\n",
    "#logging.info(\"Isolation Forest - Test Report:\\n\" + report_iforest_if)\n",
    "print(\"Isolation Forest - Test Report:\\n\" + report_iforest_if)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fa46b4",
   "metadata": {},
   "source": [
    "### IF MCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec9af7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcc_if = matthews_corrcoef(true_labels_if, val_anomaly_if)\n",
    "print(\"Matthews Correlation Coefficient: \", mcc_if)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c30aad",
   "metadata": {},
   "source": [
    "### IF Balanced Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c822d8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_acc = balanced_accuracy_score(true_labels_if, val_anomaly_if)\n",
    "print(\"Balanced Accuracy: \", balanced_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e136e11a",
   "metadata": {},
   "source": [
    "### IF AUC-Kurven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e29c7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_scores = -iforest.decision_function(val_errors.reshape(-1,1))\n",
    "y_val_seq = np.array([y_val_full[i + seq_length - 1] for i in range(len(val_scores))])\n",
    "true_labels = y_val_seq.astype(int)\n",
    "\n",
    "fpr, tpr, _ = roc_curve(true_labels, val_scores)\n",
    "roc_auc = roc_auc_score(true_labels, val_scores)\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(true_labels, val_scores)\n",
    "pr_auc = average_precision_score(true_labels, val_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add85360",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# ROC Plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.3f}\")\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve (Validation)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('roc_curve_if.png', dpi=300)\n",
    "plt.close()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc89f814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PR Plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(recall, precision, label=f\"AP = {pr_auc:.3f}\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve (Validation)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('pr_curve_if.png', dpi=300)\n",
    "plt.close()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142607f1",
   "metadata": {},
   "source": [
    "# Modell 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c53e25c",
   "metadata": {},
   "source": [
    "## One-Class SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9085760",
   "metadata": {},
   "outputs": [],
   "source": [
    "ocsvm = OneClassSVM(nu=0.005, gamma=50)\n",
    "ocsvm.fit(train_errors.reshape(-1, 1))\n",
    "\n",
    "test_preds_ocsvm = ocsvm.predict(test_errors.reshape(-1, 1))\n",
    "test_anomaly_ocsvm = (test_preds_ocsvm == -1).astype(int)\n",
    "\n",
    "y_test_seq_ocsvm = np.array([y_test_full[i + seq_length - 1] for i in range(len(test_anomaly_ocsvm))])\n",
    "true_labels_ocsvm = y_test_seq.astype(int)\n",
    "\n",
    "report_ocsvm = classification_report(true_labels_ocsvm, test_anomaly_ocsvm)\n",
    "#logging.info(\"One-Class SVM - Test Report:\\n\" + report_ocsvm)\n",
    "print(\"One-Class SVM - Test Report:\\n\" + report_ocsvm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296736bf",
   "metadata": {},
   "source": [
    "### OCSVM MCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807a8958",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcc = matthews_corrcoef(true_labels_ocsvm, test_anomaly_ocsvm)\n",
    "#logging.info(\"Matthews Correlation Coefficient: %f\", mcc)\n",
    "print(\"Matthews Correlation Coefficient:\", mcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8df4624",
   "metadata": {},
   "source": [
    "### OCSVM Balanced Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f42ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_acc = balanced_accuracy_score(true_labels_ocsvm, test_anomaly_ocsvm)\n",
    "#logging.info(\"Balanced Accuracy: %f\", balanced_acc)\n",
    "print(\"Balanced Accuracy: \", balanced_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80340a9",
   "metadata": {},
   "source": [
    "### OCSVM AUC-Kurven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8b1fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_scores_ocsvm = -ocsvm.decision_function(val_errors.reshape(-1,1))\n",
    "y_val_seq_ocsvm = np.array([y_val_full[i + seq_length - 1] for i in range(len(val_scores_ocsvm))])\n",
    "true_labels_ocsvm = y_val_seq_ocsvm.astype(int)\n",
    "\n",
    "fpr, tpr, _ = roc_curve(true_labels_ocsvm, val_scores_ocsvm)\n",
    "roc_auc = roc_auc_score(true_labels_ocsvm, val_scores_ocsvm)\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(true_labels_ocsvm, val_scores_ocsvm)\n",
    "pr_auc = average_precision_score(true_labels_ocsvm, val_scores_ocsvm)\n",
    "# Plotten\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# ROC OCSVM\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.3f}\")\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve (Validation)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('roc_curve_ocsvm.png', dpi=300)\n",
    "plt.close()\n",
    "plt.show()\n",
    "\n",
    "# PR OCSVM\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(recall, precision, label=f\"AP = {pr_auc:.3f}\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve (Validation)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('pr_curve_ocsvm.png', dpi=300)\n",
    "plt.close()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbec00d7",
   "metadata": {},
   "source": [
    "# Modell 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d99cac7",
   "metadata": {},
   "source": [
    "## DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97aea0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps = 0.05, min_samples = 40)\n",
    "\n",
    "dbscan_labels = dbscan.fit_predict(test_errors.reshape(-1, 1))\n",
    "dbscan_anomaly = (dbscan_labels == -1).astype(int)\n",
    "\n",
    "y_test_seq_dbscan = np.array([y_test_full[i + seq_length - 1] for i in range(len(dbscan_anomaly))])\n",
    "true_labels_dbscan = y_test_seq_dbscan.astype(int)\n",
    "#logging.info(\"\\n\" + classification_report(true_labels_dbscan, dbscan_anomaly))\n",
    "print(\"\\n\" + classification_report(true_labels_dbscan, dbscan_anomaly))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab11cd46",
   "metadata": {},
   "source": [
    "### DBSCAN MCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5a46a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcc = matthews_corrcoef(true_labels_dbscan, dbscan_anomaly)\n",
    "#logging.info(\"Matthews Correlation Coefficient: %f\", mcc)\n",
    "print(\"Matthews Correlation Coefficient: %f\", mcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5811f342",
   "metadata": {},
   "source": [
    "### DBSCAN Balanced Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a53ffc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_acc = balanced_accuracy_score(true_labels_dbscan, dbscan_anomaly)\n",
    "#logging.info(\"Balanced Accuracy: %f\", balanced_acc)\n",
    "print(\"Balanced Accuracy: %f\", balanced_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2569e8b7",
   "metadata": {},
   "source": [
    "### DBSCAN AUC-Kurven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc51f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = dbscan_anomaly\n",
    "\n",
    "fpr, tpr, _ = roc_curve(true_labels_dbscan, scores)\n",
    "roc_auc = roc_auc_score(true_labels_dbscan, scores)\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(true_labels_dbscan, scores)\n",
    "pr_auc = average_precision_score(true_labels_dbscan, scores)\n",
    "plt.figure(figsize=(12, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd99071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC-Kurve\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.3f}\")\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve (DBSCAN)\")\n",
    "plt.legend()\n",
    "plt.savefig('roc_curve_dbscan.png', dpi=300)\n",
    "plt.close()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd3b542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PR-Kurve\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(recall, precision, label=f\"AP = {pr_auc:.3f}\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve (DBSCAN)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('pr_curve_dbscan.png', dpi=300)\n",
    "plt.close()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9f66d3",
   "metadata": {},
   "source": [
    "## Cross Validation Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85056e1",
   "metadata": {},
   "source": [
    "### Für LSTM-AE und IF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a00c081",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import numpy as np\n",
    "\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "all_precisions, all_recalls, all_f1s, all_roc_aucs = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X_test_full)):\n",
    "    print(f\"Fold {fold + 1}/{n_splits}\")\n",
    "\n",
    "    model.fit(train_gen, validation_data=val_gen, epochs=50, callbacks=[early_stop], verbose=0)\n",
    "\n",
    "    iforest = IsolationForest()\n",
    "    iforest.fit(train_errors.reshape(-1, 1))\n",
    "\n",
    "    test_preds_if = iforest.predict(test_errors.reshape(-1, 1))\n",
    "    val_anomaly_if = (test_preds_if == -1).astype(int)\n",
    "\n",
    "    y_test_seq_if = np.array([y_test_full[i + seq_length- 1] for i in range(len(val_anomaly_if))])\n",
    "    true_labels_if = y_test_seq_if.astype(int)\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, y_pred, average='binary')\n",
    "    roc_auc = roc_auc_score(true_labels, iforest.decision_function(test_errors.reshape(-1, 1)) * -1)\n",
    "\n",
    "    all_precisions.append(precision)\n",
    "    all_recalls.append(recall)\n",
    "    all_f1s.append(f1)\n",
    "    all_roc_aucs.append(roc_auc)\n",
    "\n",
    "    print(f\"Mean Precision: {np.mean(all_precisions):.3f} ± {np.std(all_precisions):.3f}\")\n",
    "    print(f\"Mean Recall: {np.mean(all_recalls):.3f} ± {np.std(all_recalls):.3f}\")\n",
    "    print(f\"Mean F1-Score: {np.mean(all_f1s):.3f} ± {np.std(all_f1s):.3f}\")\n",
    "    print(f\"Mean ROC-AUC: {np.mean(all_roc_aucs):.3f} ± {np.std(all_roc_aucs):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe55044",
   "metadata": {},
   "source": [
    "### Für LSTM-AE und OCSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d53ac91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import numpy as np\n",
    "\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "all_precisions, all_recalls, all_f1s, all_roc_aucs = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X_test_full)):\n",
    "    print(f\"Fold {fold + 1}/{n_splits}\")\n",
    "\n",
    "    model.fit(train_gen, validation_data=val_gen, epochs=50, callbacks=[early_stop], verbose=0)\n",
    "    ocsvm = OneClassSVM(nu=0.005, gamma=50)\n",
    "    ocsvm.fit(train_errors.reshape(-1, 1))\n",
    "\n",
    "    test_preds_ocsvm = ocsvm.predict(test_errors.reshape(-1, 1))\n",
    "    test_anomaly_ocsvm = (test_preds_ocsvm == -1).astype(int)\n",
    "\n",
    "    y_test_seq_ocsvm = np.array([y_test_full[i + seq_length - 1] for i in range(len(test_anomaly_ocsvm))])\n",
    "    true_labels_ocsvm = y_test_seq.astype(int)\n",
    "\n",
    "    report_ocsvm = classification_report(true_labels_ocsvm, test_anomaly_ocsvm)\n",
    "\n",
    "    all_precisions.append(precision)\n",
    "    all_recalls.append(recall)\n",
    "    all_f1s.append(f1)\n",
    "    all_roc_aucs.append(roc_auc)\n",
    "\n",
    "    print(f\"Mean Precision: {np.mean(all_precisions):.3f} ± {np.std(all_precisions):.3f}\")\n",
    "    print(f\"Mean Recall: {np.mean(all_recalls):.3f} ± {np.std(all_recalls):.3f}\")\n",
    "    print(f\"Mean F1-Score: {np.mean(all_f1s):.3f} ± {np.std(all_f1s):.3f}\")\n",
    "    print(f\"Mean ROC-AUC: {np.mean(all_roc_aucs):.3f} ± {np.std(all_roc_aucs):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4e07bf",
   "metadata": {},
   "source": [
    "### Für LSTM-AE und DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdb81bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import numpy as np\n",
    "\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "all_precisions, all_recalls, all_f1s, all_roc_aucs = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X_test_full)):\n",
    "    print(f\"Fold {fold + 1}/{n_splits}\")\n",
    "\n",
    "    model.fit(train_gen, validation_data=val_gen, epochs=50, callbacks=[early_stop], verbose=0)\n",
    "    dbscan = DBSCAN(eps = 0.05, min_samples = 40)\n",
    "\n",
    "    dbscan_labels = dbscan.fit_predict(test_errors.reshape(-1, 1))\n",
    "    dbscan_anomaly = (dbscan_labels == -1).astype(int)\n",
    "\n",
    "    y_test_seq_dbscan = np.array([y_test_full[i + seq_length - 1] for i in range(len(dbscan_anomaly))])\n",
    "    true_labels_dbscan = y_test_seq_dbscan.astype(int)\n",
    "    \n",
    "    all_precisions.append(precision)\n",
    "    all_recalls.append(recall)\n",
    "    all_f1s.append(f1)\n",
    "    all_roc_aucs.append(roc_auc)\n",
    "\n",
    "    print(f\"Mean Precision: {np.mean(all_precisions):.3f} ± {np.std(all_precisions):.3f}\")\n",
    "    print(f\"Mean Recall: {np.mean(all_recalls):.3f} ± {np.std(all_recalls):.3f}\")\n",
    "    print(f\"Mean F1-Score: {np.mean(all_f1s):.3f} ± {np.std(all_f1s):.3f}\")\n",
    "    print(f\"Mean ROC-AUC: {np.mean(all_roc_aucs):.3f} ± {np.std(all_roc_aucs):.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
