{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb6abdb9",
   "metadata": {},
   "source": [
    "# Ein Hybridmodell mit LSTM-AE, DBSCAN und IF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8183868f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-28 12:22:07.583985: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "import logging\n",
    "from tensorflow.keras.layers import TimeDistributed, Dense, LSTM, Dropout, LayerNormalization, Input, Add, Bidirectional, RepeatVector\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "import sys\n",
    "from keras.layers import LSTM, Dropout, LayerNormalization, Add, TimeDistributed, Dense\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve, average_precision_score\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b37113",
   "metadata": {},
   "source": [
    "## 1. Vorbereitung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6d26b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# print(torch.cuda.is_available())\n",
    "# print(torch.cuda.get_device_name(0))\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# # import os\n",
    "# # import tensorflow as tf\n",
    "\n",
    "# # num_threads = os.cpu_count()\n",
    "# # tf.config.threading.set_inter_op_parallelism_threads(num_threads)\n",
    "# # tf.config.threading.set_intra_op_parallelism_threads(num_threads)\n",
    "# # print(f\"Verwendete CPU Threads: {num_threads}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e44ba590",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185398f1",
   "metadata": {},
   "source": [
    "#### Daten laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb5a6c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_json(\"train_logs.jsonl\", lines=True)\n",
    "data_test = pd.read_json(\"test_logs.jsonl\", lines=True)\n",
    "data_val = pd.read_json(\"val_logs.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "321cb5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full = pd.DataFrame(data_train)\n",
    "X_test_full = pd.DataFrame(data_test)\n",
    "X_val_full = pd.DataFrame(data_val)\n",
    "\n",
    "# data_test['label'] = data_test['details'].apply(lambda x: x.get('label', None))\n",
    "# data_val['label'] = data_val['details'].apply(lambda x: x.get('label', None))\n",
    "y_test_full = data_test[\"label\"]\n",
    "y_val_full = data_val[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b904244",
   "metadata": {},
   "source": [
    "#### Automatisch alles in Numerische oder Kategorische Daten einteilen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aeaa7cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "def is_missing(val):\n",
    "    return val is None or (isinstance(val, float) and np.isnan(val))\n",
    "\n",
    "def flatten_log_entry(log, parent_key='', sep='.'):\n",
    "    items = []\n",
    "    for k, v in log.items():\n",
    "        new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
    "        if isinstance(v, dict):\n",
    "            items.extend(flatten_log_entry(v, new_key, sep=sep).items())\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)\n",
    "\n",
    "def auto_encode_features(logs, one_hot_numeric=False, label_encoders=None, onehot_encoders=None, fit=True):\n",
    "    # Logs flach machen\n",
    "    flat_logs = [flatten_log_entry(log) for log in logs]\n",
    "\n",
    "    if label_encoders is None:\n",
    "        label_encoders = {}\n",
    "    if onehot_encoders is None:\n",
    "        onehot_encoders = {}\n",
    "\n",
    "    # Encoder vorbereiten\n",
    "    for key in flat_logs[0].keys():\n",
    "        values = []\n",
    "        for log in flat_logs:\n",
    "            val = log.get(key)\n",
    "\n",
    "            if is_missing(val):\n",
    "                val = \"__MISSING__\"\n",
    "            elif isinstance(val, (list, dict)):\n",
    "                print(f\"Feature '{key}' enthält nicht-skalaren Wert – wird als String gespeichert: {val}\")\n",
    "                val = str(val)\n",
    "\n",
    "            values.append(val)\n",
    "\n",
    "        if fit:\n",
    "            try:\n",
    "                le = LabelEncoder()\n",
    "                le.fit(values)\n",
    "                label_encoders[key] = le\n",
    "            except Exception as e:\n",
    "                print(f\"Fehler beim Enkodieren von Feature '{key}': {e}\")\n",
    "                continue\n",
    "\n",
    "    # Feature-Werte transformieren\n",
    "    encoded_logs = []\n",
    "    for log in flat_logs:\n",
    "        encoded_log = {}\n",
    "        for key, le in label_encoders.items():\n",
    "            val = log.get(key, \"__MISSING__\")\n",
    "            if is_missing(val):\n",
    "                val = \"__MISSING__\"\n",
    "            elif isinstance(val, (list, dict)):\n",
    "                val = str(val)\n",
    "            try:\n",
    "                encoded_log[key] = le.transform([val])[0]\n",
    "            except ValueError:\n",
    "                encoded_log[key] = -1  # unbekannte Kategorie\n",
    "        encoded_logs.append(encoded_log)\n",
    "\n",
    "    return encoded_logs, label_encoders, onehot_encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3ff107",
   "metadata": {},
   "source": [
    "#### Werte aus vorheriger Funktion vereinigen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4d0002f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dicts_to_feature_matrix(encoded_logs):\n",
    "    feature_names = sorted({key for d in encoded_logs for key in d.keys()})\n",
    "\n",
    "    X = np.zeros((len(encoded_logs), len(feature_names)), dtype=np.float32)\n",
    "\n",
    "    for i, d in enumerate(encoded_logs):\n",
    "        for j, feat in enumerate(feature_names):\n",
    "            if feat in d:\n",
    "                X[i, j] = d[feat]\n",
    "\n",
    "    return X, feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d825cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_train = X_train_full.to_dict(orient='records')\n",
    "#logs_train = events\n",
    "logs_test = X_test_full.to_dict(orient='records')\n",
    "logs_val = X_val_full.to_dict(orient='records')\n",
    "\n",
    "encoded_logs, label_encoders, onehot_encoders = auto_encode_features(\n",
    "    logs_train, one_hot_numeric=False, fit=True\n",
    ")\n",
    "X_train, feature_names = dicts_to_feature_matrix(encoded_logs)\n",
    "\n",
    "encoded_test_logs, _, _ = auto_encode_features(\n",
    "    logs_test, one_hot_numeric=False,\n",
    "    label_encoders=label_encoders, onehot_encoders=onehot_encoders, fit=False\n",
    ")\n",
    "X_test, _ = dicts_to_feature_matrix(encoded_test_logs)\n",
    "\n",
    "encoded_val_logs, _, _ = auto_encode_features(\n",
    "    logs_val, one_hot_numeric=False,\n",
    "    label_encoders=label_encoders, onehot_encoders=onehot_encoders, fit=False\n",
    ")\n",
    "X_val, _ = dicts_to_feature_matrix(encoded_val_logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b55383",
   "metadata": {},
   "source": [
    "#### Skalierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3445ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_val_scaled = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f955d4",
   "metadata": {},
   "source": [
    "### Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad52d0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 45\n",
    "batch_size = 32\n",
    "\n",
    "encoder_layers = [128, 64]\n",
    "decoder_layers = [64, 128]\n",
    "\n",
    "#dropout_rate = 0.1\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31049ba2",
   "metadata": {},
   "source": [
    "### Sequenzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b87923e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceToSequenceGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, data, seq_length, batch_size, pad_last=True):\n",
    "        self.data = data\n",
    "        self.seq_length = seq_length\n",
    "        self.batch_size = batch_size\n",
    "        self.pad_last = pad_last\n",
    "\n",
    "        self.indices = np.arange(len(data) - seq_length)\n",
    "        \n",
    "        # Wenn Padding aktiv ist und etwas übrig bleibt\n",
    "        if pad_last and (len(data) % seq_length != 0):\n",
    "            self.include_last = True\n",
    "        else:\n",
    "            self.include_last = False\n",
    "\n",
    "    def __len__(self):\n",
    "        base = (len(self.indices) + self.batch_size - 1) // self.batch_size\n",
    "        return base + (1 if self.include_last else 0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx < len(self) - 1 or not self.include_last:\n",
    "            batch_idx = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "            X_batch = np.array([self.data[i:i + self.seq_length] for i in batch_idx])\n",
    "        else:\n",
    "            # letzte Sequenz mit Padding\n",
    "            last_seq = self.data[-self.seq_length:]\n",
    "            if len(last_seq) < self.seq_length:\n",
    "                padding_len = self.seq_length - len(last_seq)\n",
    "                padding = np.zeros((padding_len, self.data.shape[1]))\n",
    "                last_seq = np.vstack((last_seq, padding))\n",
    "            X_batch = np.expand_dims(last_seq, axis=0)\n",
    "\n",
    "        return X_batch, X_batch\n",
    "\n",
    "train_gen = SequenceToSequenceGenerator(X_train_scaled, seq_length, batch_size)\n",
    "val_gen = SequenceToSequenceGenerator(X_val_scaled, seq_length, batch_size)\n",
    "test_gen = SequenceToSequenceGenerator(X_test_scaled, seq_length, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33d7452",
   "metadata": {},
   "source": [
    "## 2. LSTM-AE implementieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8edbf86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-28 12:45:29.326616: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">150,528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">164,352</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ repeat_vector (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,626</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m18\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │       \u001b[38;5;34m150,528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │       \u001b[38;5;34m164,352\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m98,816\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ repeat_vector (\u001b[38;5;33mRepeatVector\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m98,816\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_4 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │       \u001b[38;5;34m263,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m18\u001b[0m)         │         \u001b[38;5;34m4,626\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">780,306</span> (2.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m780,306\u001b[0m (2.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">780,306</span> (2.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m780,306\u001b[0m (2.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Bidirectional, LSTM, RepeatVector, TimeDistributed, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "n_features = X_train_scaled.shape[1]\n",
    "\n",
    "inputs = Input(shape=(seq_length, n_features))\n",
    "x = inputs\n",
    "\n",
    "# Tieferer Encoder mit bidirektionalen LSTMs\n",
    "for units in encoder_layers:\n",
    "    x = Bidirectional(LSTM(units, return_sequences=True))(x)\n",
    "    #x = Dropout(dropout_rate)(x)\n",
    "\n",
    "# Letzte Encoder-Schicht ohne return_sequences, nur den letzten Output\n",
    "encoded = Bidirectional(LSTM(encoder_layers[-1]))(x)\n",
    "\n",
    "# Tieferer Decoder\n",
    "x = RepeatVector(seq_length)(encoded)\n",
    "for units in decoder_layers:\n",
    "    x = Bidirectional(LSTM(units, return_sequences=True))(x)\n",
    "    #x = Dropout(dropout_rate)(x)\n",
    "\n",
    "outputs = TimeDistributed(Dense(n_features, activation='linear'))(x)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "model.compile(optimizer=Adam(learning_rate), loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b747efe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ueay/bachelorarbeit-projekt/env/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m853/853\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 169ms/step - loss: 0.7904 - val_loss: 0.7206\n",
      "Epoch 2/50\n",
      "\u001b[1m853/853\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 170ms/step - loss: 0.8050 - val_loss: 0.7143\n",
      "Epoch 3/50\n",
      "\u001b[1m853/853\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 172ms/step - loss: 0.7703 - val_loss: 0.7043\n",
      "Epoch 4/50\n",
      "\u001b[1m853/853\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 168ms/step - loss: 0.7044 - val_loss: 0.7678\n",
      "Epoch 5/50\n",
      "\u001b[1m853/853\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 168ms/step - loss: 0.7493 - val_loss: 0.6905\n",
      "Epoch 6/50\n",
      "\u001b[1m853/853\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 167ms/step - loss: 0.7336 - val_loss: 0.6981\n",
      "Epoch 7/50\n",
      "\u001b[1m853/853\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 170ms/step - loss: 0.7191 - val_loss: 0.7850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x72068ce4b920>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "model.fit(train_gen, epochs=50, validation_data=val_gen, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5ebaae",
   "metadata": {},
   "source": [
    "### Umwandlung der Daten für nächste Modelle: Rekonstruktionsfehler berechnen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81ede0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reconstruction_errors(gen, model):\n",
    "    errors = []\n",
    "    for i in range(len(gen)):\n",
    "        X_batch, _ = gen[i]\n",
    "        pred = model.predict(X_batch, verbose=0)\n",
    "        batch_errors = np.mean(np.square(X_batch - pred), axis=(1, 2))\n",
    "        errors.extend(batch_errors)\n",
    "    return np.array(errors)\n",
    "\n",
    "train_errors = get_reconstruction_errors(train_gen, model)\n",
    "val_errors = get_reconstruction_errors(val_gen, model)\n",
    "test_errors = get_reconstruction_errors(test_gen, model)\n",
    "#reconstruction_errors = get_reconstruction_errors(test_gen, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00451659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import precision_recall_curve, precision_recall_fscore_support, roc_auc_score\n",
    "# import numpy as np\n",
    "\n",
    "y_test_seq = np.array([\n",
    "    int(np.any(y_test_full[i : i + seq_length] == 1))\n",
    "    for i in range(len(test_errors))\n",
    "])\n",
    "\n",
    "#true_labels = y_test_seq.astype(int)\n",
    "\n",
    "# precisions, recalls, thresholds = precision_recall_curve(true_labels, test_errors)\n",
    "# f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-10)\n",
    "\n",
    "# best_idx = np.argmax(f1_scores)\n",
    "# optimal_threshold = thresholds[best_idx]\n",
    "\n",
    "# y_pred = (test_errors > optimal_threshold).astype(int)\n",
    "\n",
    "# precision, recall, f1, _ = precision_recall_fscore_support(true_labels, y_pred, average='binary')\n",
    "# roc_auc = roc_auc_score(true_labels, test_errors)\n",
    "\n",
    "# print(f\"Best Threshold by F1: {optimal_threshold:.5f}\")\n",
    "# print(f\"Precision: {precision:.3f}, Recall: {recall:.3f}, F1: {f1:.3f}, ROC-AUC: {roc_auc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7452d490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler_rec = StandardScaler()\n",
    "# scaler_rec.fit(train_errors.reshape(-1, 1))\n",
    "# test_errors_scaled = scaler_rec.transform(test_errors.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1734c09",
   "metadata": {},
   "source": [
    "# Modell 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2c9f11",
   "metadata": {},
   "source": [
    "## Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6c7b6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IsolationForest Best Threshold by F1: -0.2633\n",
      "Precision: 0.6533, Recall: 0.5861, F1: 0.6179, ROC-AUC: 0.7442, AUC-PR: 0.4105\n",
      "Matthews Correlation Coefficient: 0.5932, Balanced Accuracy: 0.7820, Accuracy: 0.9517\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iforest = IsolationForest(random_state=42, contamination=0.0008, max_samples = 'auto')\n",
    "iforest.fit(train_errors.reshape(-1, 1))\n",
    "\n",
    "scores_if = iforest.decision_function(test_errors.reshape(-1, 1))\n",
    "precisions_if, recalls_if, thresholds_if = precision_recall_curve(y_test_seq, -scores_if)\n",
    "best_f1_scores_if = 2 * (precisions_if * recalls_if) / (precisions_if + recalls_if + 1e-10)\n",
    "best_idx_if = np.argmax(best_f1_scores_if)\n",
    "optimal_threshold_if = thresholds_if[best_idx_if]\n",
    "y_pred_if = ((-scores_if) > optimal_threshold_if).astype(int)\n",
    "\n",
    "precision_if, recall_if, f1_if, _ = precision_recall_fscore_support(y_test_seq, y_pred_if, average='binary')\n",
    "roc_auc_if = roc_auc_score(y_test_seq, -scores_if)\n",
    "pr_auc_if = average_precision_score(y_test_seq, y_pred_if)\n",
    "fpr, tpr, _ = roc_curve(y_test_seq, y_pred_if)\n",
    "accuracy_if = accuracy_score(y_test_seq, y_pred_if)\n",
    "\n",
    "mcc_if = matthews_corrcoef(y_test_seq, y_pred_if)\n",
    "balanced_acc_if = balanced_accuracy_score(y_test_seq, y_pred_if)\n",
    "\n",
    "print(f\"IsolationForest Best Threshold by F1: {optimal_threshold_if:.4f}\")\n",
    "print(f\"Precision: {precision_if:.4f}, Recall: {recall_if:.4f}, F1: {f1_if:.4f}, ROC-AUC: {roc_auc_if:.4f}, AUC-PR: {pr_auc_if:.4f}\")\n",
    "print(f\"Matthews Correlation Coefficient: {mcc_if:.4f}, Balanced Accuracy: {balanced_acc_if:.4f}, Accuracy: {accuracy_if:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142607f1",
   "metadata": {},
   "source": [
    "# Modell 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c53e25c",
   "metadata": {},
   "source": [
    "## One-Class SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9085760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-Class SVM Best Threshold by F1: -0.0181\n",
      "Precision: 0.6568, Recall: 0.6247, F1: 0.6403, ROC-AUC: 0.6866, AUC-PR: 0.4353,MCC: 0.6155, Balanced Accuracy: 0.8007, Accuracy: 0.9532\n"
     ]
    }
   ],
   "source": [
    "ocsvm = OneClassSVM(nu = 0.0008, gamma='scale', kernel = 'rbf')\n",
    "ocsvm.fit(train_errors.reshape(-1,1))\n",
    "\n",
    "scores_ocsvm = ocsvm.decision_function(test_errors.reshape(-1, 1))  # kleiner = anomal\n",
    "precisions_ocsvm, recalls_ocsvm, thresholds_ocsvm = precision_recall_curve(y_test_seq, -scores_ocsvm)\n",
    "f1_scores_ocsvm = 2 * (precisions_ocsvm * recalls_ocsvm) / (precisions_ocsvm + recalls_ocsvm + 1e-10)\n",
    "best_idx_ocsvm = np.argmax(f1_scores_ocsvm)\n",
    "optimal_threshold_ocsvm = thresholds_ocsvm[best_idx_ocsvm]\n",
    "\n",
    "# Vorhersagen auf Testset\n",
    "y_pred_ocsvm = ((-scores_ocsvm) > optimal_threshold_ocsvm).astype(int)\n",
    "\n",
    "# Metriken\n",
    "precision_ocsvm, recall_ocsvm, f1_ocsvm, _ = precision_recall_fscore_support(y_test_seq, y_pred_ocsvm, average='binary')\n",
    "roc_auc_ocsvm = roc_auc_score(y_test_seq, -scores_ocsvm)\n",
    "fpr, tpr, _ = roc_curve(y_test_seq, y_pred_ocsvm)\n",
    "pr_auc_ocsvm = average_precision_score(y_test_seq, y_pred_ocsvm)\n",
    "accuracy_ocsvm = accuracy_score(y_test_seq, y_pred_ocsvm)\n",
    "\n",
    "mcc_ocsvm = matthews_corrcoef(y_test_seq, y_pred_ocsvm)\n",
    "balanced_acc_ocsvm = balanced_accuracy_score(y_test_seq, y_pred_ocsvm)\n",
    "\n",
    "print(f\"One-Class SVM Best Threshold by F1: {optimal_threshold_ocsvm:.4f}\")\n",
    "print(f\"Precision: {precision_ocsvm:.4f}, Recall: {recall_ocsvm:.4f}, F1: {f1_ocsvm:.4f}, ROC-AUC: {roc_auc_ocsvm:.4f}, AUC-PR: {pr_auc_ocsvm:.4f},MCC: {mcc_ocsvm:.4f}, Balanced Accuracy: {balanced_acc_ocsvm:.4f}, Accuracy: {accuracy_ocsvm:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbec00d7",
   "metadata": {},
   "source": [
    "# Modell 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d99cac7",
   "metadata": {},
   "source": [
    "## DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97aea0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passender eps-Wert: 0.05, Anomalien: 29\n",
      "Precision: 1.0000, Recall: 0.0746, F1: 0.1388\n",
      "MCC: 0.2644, Balanced Accuracy: 0.5373\n",
      "ROC-AUC: 0.5373, AUC-PR: 0.1362, Accuracy: 0.9383\n"
     ]
    }
   ],
   "source": [
    "for eps in np.linspace(0.01, 1.0, 100):\n",
    "    dbscan = DBSCAN(min_samples=3, metric='euclidean', eps=eps)\n",
    "    labels = dbscan.fit_predict(test_errors.reshape(-1, 1))\n",
    "    n_anomalies = np.sum(labels == -1)\n",
    "    if abs(n_anomalies - 31) <= 2:\n",
    "        print(f'Passender eps-Wert: {eps}, Anomalien: {n_anomalies}')\n",
    "        break\n",
    "\n",
    "y_pred_dbscan = (labels == -1).astype(int)\n",
    "\n",
    "# Metriken berechnen\n",
    "precision_dbscan, recall_dbscan, f1_dbscan, _ = precision_recall_fscore_support(y_test_seq, y_pred_dbscan, average='binary')\n",
    "roc_auc_dbscan = roc_auc_score(y_test_seq, y_pred_dbscan)\n",
    "pr_auc_dbscan = average_precision_score(y_test_seq, y_pred_dbscan)\n",
    "accuracy_dbscan = accuracy_score(y_test_seq, y_pred_dbscan)\n",
    "mcc_dbscan = matthews_corrcoef(y_test_seq, y_pred_dbscan)\n",
    "balanced_acc_dbscan = balanced_accuracy_score(y_test_seq, y_pred_dbscan)\n",
    "\n",
    "print(f\"Precision: {precision_dbscan:.4f}, Recall: {recall_dbscan:.4f}, F1: {f1_dbscan:.4f}\")\n",
    "print(f\"MCC: {mcc_dbscan:.4f}, Balanced Accuracy: {balanced_acc_dbscan:.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_dbscan:.4f}, AUC-PR: {pr_auc_dbscan:.4f}, Accuracy: {accuracy_dbscan:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f3e5bf",
   "metadata": {},
   "source": [
    "### Standardabweichung und Varianz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b374584",
   "metadata": {},
   "source": [
    "#### Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "439aa81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IF, Seq 25, F1-Score, Varianz (Stichprobe): 0.0001238180000000003\n",
      "IF, Seq 25, MCC, Varianz (Stichprobe): 0.0002203369999999998\n",
      "IF, Seq 25, BA, Varianz (Stichprobe): 4.6649999999999914e-05\n",
      "IF, Seq 25, IF, Standardabweichung (Stichprobe): 0.011127353683603318\n",
      "IF, Seq 25, MCC, Standardabweichung (Stichprobe): 0.014843752894736554\n",
      "IF, Seq 25, BA, Standardabweichung (Stichprobe): 0.006830080526611668\n",
      "IF, Seq 45, F1-Score, Varianz (Stichprobe): 0.00031796700000000016\n",
      "IF, Seq 45, MCC, Varianz (Stichprobe): 0.0003822950000000013\n",
      "IF, Seq 45, BA, Varianz (Stichprobe): 7.349199999999987e-05\n",
      "IF, Seq 45, F1-Score, Standardabweichung (Stichprobe): 0.017831629202066764\n",
      "IF, Seq 45, MCC, Standardabweichung (Stichprobe): 0.019552365585780183\n",
      "IF, Seq 45, BA, Standardabweichung (Stichprobe): 0.008572747517569842\n"
     ]
    }
   ],
   "source": [
    "if_25_f1 = [0.7596, 0.7610, 0.7494, 0.7368, 0.7639]\n",
    "if_25_mcc = [0.7647, 0.7550, 0.7346, 0.7720, 0.7673]\n",
    "if_25_ba = [0.8165, 0.8128, 0.8209, 0.8141, 0.8297]\n",
    "\n",
    "if_45_f1 = [0.6094, 0.6379, 0.6289, 0.5918, 0.6179]\n",
    "if_45_mcc = [0.5819, 0.6126, 0.6024, 0.5619, 0.5932]\n",
    "if_45_ba = [0.7875, 0.8015, 0.8005, 0.7971, 0.7820]\n",
    "\n",
    "# Varianz (Population)\n",
    "if_25_f1_varianz = np.var(if_25_f1)\n",
    "if_25_mcc_varianz = np.var(if_25_mcc)\n",
    "if_25_ba_varianz = np.var(if_25_ba)\n",
    "\n",
    "if_45_f1_varianz = np.var(if_45_f1)\n",
    "if_45_mcc_varianz = np.var(if_45_mcc)\n",
    "if_45_ba_varianz = np.var(if_45_ba)\n",
    "\n",
    "# Varianz (Stichprobe, mit n-1 im Nenner)\n",
    "if_25_f1_varianz_stichprobe = np.var(if_25_f1, ddof=1)\n",
    "if_25_mcc_varianz_stichprobe = np.var(if_25_mcc, ddof=1)\n",
    "if_25_ba_varianz_stichprobe = np.var(if_25_ba, ddof=1)\n",
    "\n",
    "if_45_f1_varianz_stichprobe = np.var(if_45_f1, ddof=1)\n",
    "if_45_mcc_varianz_stichprobe = np.var(if_45_mcc, ddof=1)\n",
    "if_45_ba_varianz_stichprobe = np.var(if_45_ba, ddof=1)\n",
    "\n",
    "# Standardabweichung (Population)\n",
    "if_25_f1_std_pop = np.std(if_25_f1)\n",
    "if_25_mcc_std_pop = np.std(if_25_mcc)\n",
    "if_25_ba_std_pop = np.std(if_25_ba)\n",
    "\n",
    "if_45_f1_std_pop = np.std(if_45_f1)\n",
    "if_45_mcc_std_pop = np.std(if_45_mcc)\n",
    "if_45_ba_std_pop = np.std(if_45_ba)\n",
    "\n",
    "# Standardabweichung (Stichprobe)\n",
    "if_25_f1_std_stichprobe = np.std(if_25_f1, ddof=1)\n",
    "if_25_mcc_std_stichprobe = np.std(if_25_mcc, ddof=1)\n",
    "if_25_ba_std_stichprobe = np.std(if_25_ba, ddof=1)\n",
    "\n",
    "if_45_f1_std_stichprobe = np.std(if_45_f1, ddof=1)\n",
    "if_45_mcc_std_stichprobe = np.std(if_45_mcc, ddof=1)\n",
    "if_45_ba_std_stichprobe = np.std(if_45_ba, ddof=1)\n",
    "\n",
    "print(\"IF, Seq 25, F1-Score, Varianz (Stichprobe):\", if_25_f1_varianz_stichprobe)\n",
    "print(\"IF, Seq 25, MCC, Varianz (Stichprobe):\", if_25_mcc_varianz_stichprobe)\n",
    "print(\"IF, Seq 25, BA, Varianz (Stichprobe):\", if_25_ba_varianz_stichprobe)\n",
    "print(\"IF, Seq 25, IF, Standardabweichung (Stichprobe):\", if_25_f1_std_stichprobe)\n",
    "print(\"IF, Seq 25, MCC, Standardabweichung (Stichprobe):\", if_25_mcc_std_stichprobe)\n",
    "print(\"IF, Seq 25, BA, Standardabweichung (Stichprobe):\", if_25_ba_std_stichprobe)\n",
    "\n",
    "print(\"IF, Seq 45, F1-Score, Varianz (Stichprobe):\", if_45_f1_varianz_stichprobe)\n",
    "print(\"IF, Seq 45, MCC, Varianz (Stichprobe):\", if_45_mcc_varianz_stichprobe)\n",
    "print(\"IF, Seq 45, BA, Varianz (Stichprobe):\", if_45_ba_varianz_stichprobe)\n",
    "print(\"IF, Seq 45, F1-Score, Standardabweichung (Stichprobe):\", if_45_f1_std_stichprobe)\n",
    "print(\"IF, Seq 45, MCC, Standardabweichung (Stichprobe):\", if_45_mcc_std_stichprobe)\n",
    "print(\"IF, Seq 45, BA, Standardabweichung (Stichprobe):\", if_45_ba_std_stichprobe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609a888b",
   "metadata": {},
   "source": [
    "#### OCSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "69dfdcc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCSVM, Seq 25, F1-Score, Varianz (Stichprobe): 0.0005675630000000001\n",
      "OCSVM, Seq 25, MCC,Varianz (Stichprobe): 0.0009435899999999996\n",
      "OCSVM, Seq 25, BA,Varianz (Stichprobe): 8.696499999999996e-05\n",
      "OCSVM, Seq 25, F1-Score, Standardabweichung (Stichprobe): 0.023823580755209746\n",
      "OCSVM, Seq 25, MCC, Standardabweichung (Stichprobe): 0.030717910085160408\n",
      "OCSVM, Seq 25, BA, Standardabweichung (Stichprobe): 0.009325502667416913\n",
      "OCSVM, Seq 45, F1-Score,Varianz (Stichprobe): 0.00031796700000000016\n",
      "OCSVM, Seq 45, MCC, Varianz (Stichprobe): 0.0003822950000000013\n",
      "OCSVM, Seq 45, BA, Varianz (Stichprobe): 7.349199999999987e-05\n",
      "OCSVM, Seq 45, F1-Score, Standardabweichung (Stichprobe): 0.017831629202066764\n",
      "OCSVM, Seq 45, MCC, Standardabweichung (Stichprobe): 0.019552365585780183\n",
      "OCSVM, Seq 45, BA, Standardabweichung (Stichprobe): 0.008572747517569842\n"
     ]
    }
   ],
   "source": [
    "ocsvm_25_f1 = [0.7564, 0.7603, 0.7364, 0.7039, 0.7578]\n",
    "ocsvm_25_mcc = [0.7572, 0.7696, 0.7332, 0.6916, 0.7549]\n",
    "ocsvm_25_ba = [0.8256, 0.8146, 0.8227, 0.8357, 0.8369]\n",
    "\n",
    "ocsvm_45_f1 = [0.6094, 0.6379, 0.6289, 0.5918, 0.6179]\n",
    "ocsvm_45_mcc = [0.5819, 0.6126, 0.6024, 0.5619, 0.5932]\n",
    "ocsvm_45_ba = [0.7875, 0.8015, 0.8005, 0.7971, 0.7820]\n",
    "\n",
    "# Varianz (Population)\n",
    "ocsvm_25_f1_varianz = np.var(ocsvm_25_f1)\n",
    "ocsvm_25_mcc_varianz = np.var(ocsvm_25_mcc)\n",
    "ocsvm_25_ba_varianz = np.var(ocsvm_25_ba)\n",
    "\n",
    "ocsvm_45_f1_varianz = np.var(ocsvm_45_f1)\n",
    "ocsvm_45_mcc_varianz = np.var(ocsvm_45_mcc)\n",
    "ocsvm_45_ba_varianz = np.var(ocsvm_45_ba)\n",
    "\n",
    "# Varianz (Stichprobe, mit n-1 im Nenner)\n",
    "ocsvm_25_f1_varianz_stichprobe = np.var(ocsvm_25_f1, ddof=1)\n",
    "ocsvm_25_mcc_varianz_stichprobe = np.var(ocsvm_25_mcc, ddof=1)\n",
    "ocsvm_25_ba_varianz_stichprobe = np.var(ocsvm_25_ba, ddof=1)\n",
    "\n",
    "ocsvm_45_f1_varianz_stichprobe = np.var(ocsvm_45_f1, ddof=1)\n",
    "ocsvm_45_mcc_varianz_stichprobe = np.var(ocsvm_45_mcc, ddof=1)\n",
    "ocsvm_45_ba_varianz_stichprobe = np.var(ocsvm_45_ba, ddof=1)\n",
    "\n",
    "# Standardabweichung (Population)\n",
    "ocsvm_25_f1_std_pop = np.std(ocsvm_25_f1)\n",
    "ocsvm_25_mcc_std_pop = np.std(ocsvm_25_mcc)\n",
    "ocsvm_25_ba_std_pop = np.std(ocsvm_25_ba)\n",
    "\n",
    "ocsvm_45_f1_std_pop = np.std(ocsvm_45_f1)\n",
    "ocsvm_45_mcc_std_pop = np.std(ocsvm_45_mcc)\n",
    "ocsvm_45_ba_std_pop = np.std(ocsvm_45_ba)\n",
    "\n",
    "# Standardabweichung (Stichprobe)\n",
    "ocsvm_25_f1_std_stichprobe = np.std(ocsvm_25_f1, ddof=1)\n",
    "ocsvm_25_mcc_std_stichprobe = np.std(ocsvm_25_mcc, ddof=1)\n",
    "ocsvm_25_ba_std_stichprobe = np.std(ocsvm_25_ba, ddof=1)\n",
    "\n",
    "ocsvm_45_f1_std_stichprobe = np.std(ocsvm_45_f1, ddof=1)\n",
    "ocsvm_45_mcc_std_stichprobe = np.std(ocsvm_45_mcc, ddof=1)\n",
    "ocsvm_45_ba_std_stichprobe = np.std(ocsvm_45_ba, ddof=1)\n",
    "\n",
    "print(\"OCSVM, Seq 25, F1-Score, Varianz (Stichprobe):\", ocsvm_25_f1_varianz_stichprobe)\n",
    "print(\"OCSVM, Seq 25, MCC,Varianz (Stichprobe):\", ocsvm_25_mcc_varianz_stichprobe)\n",
    "print(\"OCSVM, Seq 25, BA,Varianz (Stichprobe):\", ocsvm_25_ba_varianz_stichprobe)\n",
    "print(\"OCSVM, Seq 25, F1-Score, Standardabweichung (Stichprobe):\", ocsvm_25_f1_std_stichprobe)\n",
    "print(\"OCSVM, Seq 25, MCC, Standardabweichung (Stichprobe):\", ocsvm_25_mcc_std_stichprobe)\n",
    "print(\"OCSVM, Seq 25, BA, Standardabweichung (Stichprobe):\", ocsvm_25_ba_std_stichprobe)\n",
    "\n",
    "print(\"OCSVM, Seq 45, F1-Score,Varianz (Stichprobe):\", ocsvm_45_f1_varianz_stichprobe)\n",
    "print(\"OCSVM, Seq 45, MCC, Varianz (Stichprobe):\", ocsvm_45_mcc_varianz_stichprobe)\n",
    "print(\"OCSVM, Seq 45, BA, Varianz (Stichprobe):\", ocsvm_45_ba_varianz_stichprobe)\n",
    "print(\"OCSVM, Seq 45, F1-Score, Standardabweichung (Stichprobe):\", ocsvm_45_f1_std_stichprobe)\n",
    "print(\"OCSVM, Seq 45, MCC, Standardabweichung (Stichprobe):\", ocsvm_45_mcc_std_stichprobe)\n",
    "print(\"OCSVM, Seq 45, BA, Standardabweichung (Stichprobe):\", ocsvm_45_ba_std_stichprobe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe4ef97",
   "metadata": {},
   "source": [
    "#### DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ae83615b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Varianz (Stichprobe): 0.003704448000000001\n",
      "Varianz (Stichprobe): 0.0038923530000000003\n",
      "Varianz (Stichprobe): 0.0003189050000000004\n",
      "Standardabweichung (Stichprobe): 0.06086417665589506\n",
      "Standardabweichung (Stichprobe): 0.06238872494289333\n",
      "Standardabweichung (Stichprobe): 0.017857911412032496\n",
      "Varianz (Stichprobe): 0.0017061099999999998\n",
      "Varianz (Stichprobe): 0.0025601580000000007\n",
      "Varianz (Stichprobe): 0.00012960699999999952\n",
      "Standardabweichung (Stichprobe): 0.04130508443279108\n",
      "Standardabweichung (Stichprobe): 0.050598003913198006\n",
      "Standardabweichung (Stichprobe): 0.011384507016116223\n"
     ]
    }
   ],
   "source": [
    "dbscan_25_f1 = [0.2278, 0.2214, 0.0846, 0.2214, 0.2086]\n",
    "dbscan_25_mcc = [0.3517, 0.3462, 0.2059, 0.3462, 0.3348]\n",
    "dbscan_25_ba = [0.5643, 0.5622, 0.5221, 0.5622, 0.5582]\n",
    "\n",
    "dbscan_45_f1 = [0.1388, 0.0501, 0.1476, 0.1432, 0.1388]\n",
    "dbscan_45_mcc = [0.2644, 0.1550, 0.2735, 0.2690, 0.2644]\n",
    "dbscan_45_ba = [0.5373, 0.5129, 0.5398, 0.5386, 0.5373]\n",
    "\n",
    "# Varianz (Population)\n",
    "dbscan_25_f1_varianz = np.var(dbscan_25_f1)\n",
    "dbscan_25_mcc_varianz = np.var(dbscan_25_mcc)\n",
    "dbscan_25_ba_varianz = np.var(dbscan_25_ba)\n",
    "\n",
    "dbscan_45_f1_varianz = np.var(dbscan_45_f1)\n",
    "dbscan_45_mcc_varianz = np.var(dbscan_45_mcc)\n",
    "dbscan_45_ba_varianz = np.var(dbscan_45_ba)\n",
    "\n",
    "# Varianz (Stichprobe, mit n-1 im Nenner)\n",
    "dbscan_25_f1_varianz_stichprobe = np.var(dbscan_25_f1, ddof=1)\n",
    "dbscan_25_mcc_varianz_stichprobe = np.var(dbscan_25_mcc, ddof=1)\n",
    "dbscan_25_ba_varianz_stichprobe = np.var(dbscan_25_ba, ddof=1)\n",
    "\n",
    "dbscan_45_f1_varianz_stichprobe = np.var(dbscan_45_f1, ddof=1)\n",
    "dbscan_45_mcc_varianz_stichprobe = np.var(dbscan_45_mcc, ddof=1)\n",
    "dbscan_45_ba_varianz_stichprobe = np.var(dbscan_45_ba, ddof=1)\n",
    "\n",
    "# Standardabweichung (Population)\n",
    "dbscan_25_f1_std_pop = np.std(dbscan_25_f1)\n",
    "dbscan_25_mcc_std_pop = np.std(dbscan_25_mcc)\n",
    "dbscan_25_ba_std_pop = np.std(dbscan_25_ba)\n",
    "\n",
    "dbscan_45_f1_std_pop = np.std(dbscan_45_f1)\n",
    "dbscan_45_mcc_std_pop = np.std(dbscan_45_mcc)\n",
    "dbscan_45_ba_std_pop = np.std(dbscan_45_ba)\n",
    "\n",
    "# Standardabweichung (Stichprobe)\n",
    "dbscan_25_f1_std_stichprobe = np.std(dbscan_25_f1, ddof=1)\n",
    "dbscan_25_mcc_std_stichprobe = np.std(dbscan_25_mcc, ddof=1)\n",
    "dbscan_25_ba_std_stichprobe = np.std(dbscan_25_ba, ddof=1)\n",
    "\n",
    "dbscan_45_f1_std_stichprobe = np.std(dbscan_45_f1, ddof=1)\n",
    "dbscan_45_mcc_std_stichprobe = np.std(dbscan_45_mcc, ddof=1)\n",
    "dbscan_45_ba_std_stichprobe = np.std(dbscan_45_ba, ddof=1)\n",
    "\n",
    "print(\"Varianz (Stichprobe):\", dbscan_25_f1_varianz_stichprobe)\n",
    "print(\"Varianz (Stichprobe):\", dbscan_25_mcc_varianz_stichprobe)\n",
    "print(\"Varianz (Stichprobe):\", dbscan_25_ba_varianz_stichprobe)\n",
    "print(\"Standardabweichung (Stichprobe):\", dbscan_25_f1_std_stichprobe)\n",
    "print(\"Standardabweichung (Stichprobe):\", dbscan_25_mcc_std_stichprobe)\n",
    "print(\"Standardabweichung (Stichprobe):\", dbscan_25_ba_std_stichprobe)\n",
    "\n",
    "\n",
    "print(\"Varianz (Stichprobe):\", dbscan_45_f1_varianz_stichprobe)\n",
    "print(\"Varianz (Stichprobe):\", dbscan_45_mcc_varianz_stichprobe)\n",
    "print(\"Varianz (Stichprobe):\", dbscan_45_ba_varianz_stichprobe)\n",
    "print(\"Standardabweichung (Stichprobe):\", dbscan_45_f1_std_stichprobe)\n",
    "print(\"Standardabweichung (Stichprobe):\", dbscan_45_mcc_std_stichprobe)\n",
    "print(\"Standardabweichung (Stichprobe):\", dbscan_45_ba_std_stichprobe)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e92d69",
   "metadata": {},
   "source": [
    "## Friedmann-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72703ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ueay/bachelorarbeit-projekt/env/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78dc8f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Friedman-Test für F1-Score ===\n",
      "Chi² = 10.000, p = 0.0067\n",
      "Signifikante Unterschiede zwischen den Modellen\n",
      "\n",
      "=== Friedman-Test für MCC ===\n",
      "Chi² = 8.400, p = 0.0150\n",
      "Signifikante Unterschiede zwischen den Modellen\n",
      "\n",
      "=== Friedman-Test für Balanced Accuracy ===\n",
      "Chi² = 10.000, p = 0.0067\n",
      "Signifikante Unterschiede zwischen den Modellen\n",
      "\n",
      "=== Friedman-Test für F1-Score ===\n",
      "Chi² = 10.000, p = 0.0067\n",
      "Signifikante Unterschiede zwischen den Modellen\n",
      "\n",
      "=== Friedman-Test für MCC ===\n",
      "Chi² = 10.000, p = 0.0067\n",
      "Signifikante Unterschiede zwischen den Modellen\n",
      "\n",
      "=== Friedman-Test für Balanced Accuracy ===\n",
      "Chi² = 10.000, p = 0.0067\n",
      "Signifikante Unterschiede zwischen den Modellen\n"
     ]
    }
   ],
   "source": [
    "import scipy as sp\n",
    "from scipy.stats import friedmanchisquare\n",
    "\n",
    "# ------------------------------\n",
    "# Ergebnisse pro Modell (in der Reihenfolge Seq-Längen 25, 35, 45)\n",
    "# ------------------------------\n",
    "\n",
    "# F1-Score\n",
    "IF_f1_25 = [0.7596, 0.7610, 0.7494, 0.7368, 0.7639]\n",
    "OCSVM_f1_25 = [0.7564, 0.7603, 0.7364, 0.7039, 0.7578]\n",
    "DBSCAN_f1_25 = [0.2278, 0.2214, 0.0846, 0.2214, 0.2086]\n",
    "\n",
    "IF_f1_45 = [0.6094, 0.6379, 0.6289, 0.5918, 0.6179]\n",
    "OCSVM_f1_45 = [0.6094, 0.6379, 0.6289, 0.5918, 0.6179]\n",
    "DBSCAN_f1_45 = [0.1388, 0.0501, 0.1476, 0.1432, 0.1388]\n",
    "\n",
    "# Matthews Correlation Coefficient (MCC)\n",
    "IF_mcc_25 = [0.7647, 0.7550, 0.7346, 0.7720, 0.7673]\n",
    "OCSVM_mcc_25 = [0.7572, 0.7696, 0.7332, 0.6916, 0.7549]\n",
    "DBSCAN_mcc_25 = [0.3517, 0.3462, 0.2059, 0.3462, 0.3348]\n",
    "\n",
    "IF_mcc_45 = [0.5819, 0.6126, 0.6024, 0.5619, 0.5932]\n",
    "OCSVM_mcc_45 = [0.5819, 0.6126, 0.6024, 0.5619, 0.5932]\n",
    "DBSCAN_mcc_45 = [0.2644, 0.1550, 0.2735, 0.2690, 0.2644]\n",
    "\n",
    "# Balanced Accuracy\n",
    "IF_bal_25 = [0.8165, 0.8128, 0.8209, 0.8141, 0.8297]\n",
    "OCSVM_bal_25 = [0.8256, 0.8146, 0.8227, 0.8357, 0.8369]\n",
    "DBSCAN_bal_25 = [0.5643, 0.5622, 0.5221, 0.5622, 0.5582]\n",
    "\n",
    "IF_bal_45 = [0.7875, 0.8015, 0.8005, 0.7971, 0.7820]\n",
    "OCSVM_bal_45 = [0.7875, 0.8015, 0.8005, 0.7971, 0.7820]\n",
    "DBSCAN_bal_45 = [0.5373, 0.5129, 0.5398, 0.5386, 0.5373]\n",
    "\n",
    "# ------------------------------\n",
    "# Funktion für Friedman-Test\n",
    "# ------------------------------\n",
    "def run_friedman(model1, model2, model3, metric_name):\n",
    "    stat, p = friedmanchisquare(model1, model2, model3)\n",
    "    print(f\"\\n=== Friedman-Test für {metric_name} ===\")\n",
    "    print(f\"Chi² = {stat:.3f}, p = {p:.4f}\")\n",
    "    if p < 0.05:\n",
    "        print(\"Signifikante Unterschiede zwischen den Modellen\")\n",
    "    else:\n",
    "        print(\"Keine signifikanten Unterschiede\")\n",
    "\n",
    "# ------------------------------\n",
    "# Tests durchführen\n",
    "# ------------------------------\n",
    "run_friedman(IF_f1_25, OCSVM_f1_25, DBSCAN_f1_25, \"F1-Score\")\n",
    "run_friedman(IF_mcc_25, OCSVM_mcc_25, DBSCAN_mcc_25, \"MCC\")\n",
    "run_friedman(IF_bal_25, OCSVM_bal_25, DBSCAN_bal_25, \"Balanced Accuracy\")\n",
    "\n",
    "run_friedman(IF_f1_45, OCSVM_f1_45, DBSCAN_f1_45, \"F1-Score\")\n",
    "run_friedman(IF_mcc_45, OCSVM_mcc_45, DBSCAN_mcc_45, \"MCC\")\n",
    "run_friedman(IF_bal_45, OCSVM_bal_45, DBSCAN_bal_45, \"Balanced Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3739ad09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq 25 - F1:\n",
      "          0         1         2\n",
      "0  1.000000  0.253784  0.004464\n",
      "1  0.253784  1.000000  0.253784\n",
      "2  0.004464  0.253784  1.000000\n",
      "Seq 25 - MCC:\n",
      "          0         1         2\n",
      "0  1.000000  0.609411  0.012310\n",
      "1  0.609411  1.000000  0.139405\n",
      "2  0.012310  0.139405  1.000000\n",
      "Seq 25 - Balanced Accuracy:\n",
      "          0         1         2\n",
      "0  1.000000  0.253784  0.253784\n",
      "1  0.253784  1.000000  0.004464\n",
      "2  0.253784  0.004464  1.000000\n",
      "Seq 45 - F1:\n",
      "         0        1        2\n",
      "0  1.00000  1.00000  0.04656\n",
      "1  1.00000  1.00000  0.04656\n",
      "2  0.04656  0.04656  1.00000\n",
      "Seq 45 - MCC:\n",
      "         0        1        2\n",
      "0  1.00000  1.00000  0.04656\n",
      "1  1.00000  1.00000  0.04656\n",
      "2  0.04656  0.04656  1.00000\n",
      "Seq 45 - Balanced Accuracy:\n",
      "         0        1        2\n",
      "0  1.00000  1.00000  0.04656\n",
      "1  1.00000  1.00000  0.04656\n",
      "2  0.04656  0.04656  1.00000\n"
     ]
    }
   ],
   "source": [
    "import scikit_posthocs as sp\n",
    "import numpy as np\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "# ==========================\n",
    "# Seq 25\n",
    "# ==========================\n",
    "\n",
    "# F1-Score\n",
    "f1_seq25 = np.array([\n",
    "    (0.7596, 0.7564, 0.2278),  # Datensatz 1: IF, OCSVM, DBSCAN\n",
    "    (0.7610, 0.7603, 0.2214),\n",
    "    (0.7494, 0.7364, 0.0846),\n",
    "    (0.7368, 0.7039, 0.2214),\n",
    "    (0.7639, 0.7578, 0.2086)\n",
    "])\n",
    "nemenyi_f1_seq25 = sp.posthoc_nemenyi_friedman(f1_seq25)\n",
    "print(\"Seq 25 - F1:\")\n",
    "print(nemenyi_f1_seq25)\n",
    "\n",
    "# MCC\n",
    "mcc_seq25 = np.array([\n",
    "    (0.7647, 0.7572, 0.3517),\n",
    "    (0.7550, 0.7696, 0.3462),\n",
    "    (0.7346, 0.7332, 0.2059),\n",
    "    (0.7720, 0.6916, 0.3462),\n",
    "    (0.7673, 0.7549, 0.3348)\n",
    "])\n",
    "nemenyi_mcc_seq25 = sp.posthoc_nemenyi_friedman(mcc_seq25)\n",
    "print(\"Seq 25 - MCC:\")\n",
    "print(nemenyi_mcc_seq25)\n",
    "\n",
    "# Balanced Accuracy\n",
    "bal_seq25 = np.array([\n",
    "    (0.8165, 0.8256, 0.5643),\n",
    "    (0.8128, 0.8146, 0.5622),\n",
    "    (0.8209, 0.8227, 0.5221),\n",
    "    (0.8141, 0.8357, 0.5622),\n",
    "    (0.8297, 0.8369, 0.5582)\n",
    "])\n",
    "nemenyi_bal_seq25 = sp.posthoc_nemenyi_friedman(bal_seq25)\n",
    "print(\"Seq 25 - Balanced Accuracy:\")\n",
    "print(nemenyi_bal_seq25)\n",
    "\n",
    "# ==========================\n",
    "# Seq 45\n",
    "# ==========================\n",
    "\n",
    "# F1-Score\n",
    "f1_seq45 = np.array([\n",
    "    (0.6094, 0.6094, 0.1388),\n",
    "    (0.6379, 0.6379, 0.0501),\n",
    "    (0.6289, 0.6289, 0.1476),\n",
    "    (0.5918, 0.5918, 0.1432),\n",
    "    (0.6179, 0.6179, 0.1388)\n",
    "])\n",
    "nemenyi_f1_seq45 = sp.posthoc_nemenyi_friedman(f1_seq45)\n",
    "print(\"Seq 45 - F1:\")\n",
    "print(nemenyi_f1_seq45)\n",
    "\n",
    "# MCC\n",
    "mcc_seq45 = np.array([\n",
    "    (0.5819, 0.5819, 0.2644),\n",
    "    (0.6126, 0.6126, 0.1550),\n",
    "    (0.6024, 0.6024, 0.2735),\n",
    "    (0.5619, 0.5619, 0.2690),\n",
    "    (0.5932, 0.5932, 0.2644)\n",
    "])\n",
    "nemenyi_mcc_seq45 = sp.posthoc_nemenyi_friedman(mcc_seq45)\n",
    "print(\"Seq 45 - MCC:\")\n",
    "print(nemenyi_mcc_seq45)\n",
    "\n",
    "# Balanced Accuracy\n",
    "bal_seq45 = np.array([\n",
    "    (0.7875, 0.7875, 0.5373),\n",
    "    (0.8015, 0.8015, 0.5129),\n",
    "    (0.8005, 0.8005, 0.5398),\n",
    "    (0.7971, 0.7971, 0.5386),\n",
    "    (0.7820, 0.7820, 0.5373)\n",
    "])\n",
    "nemenyi_bal_seq45 = sp.posthoc_nemenyi_friedman(bal_seq45)\n",
    "print(\"Seq 45 - Balanced Accuracy:\")\n",
    "print(nemenyi_bal_seq45)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24e1c605",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ueay/bachelorarbeit-projekt/env/lib/python3.12/site-packages/statsmodels/multivariate/multivariate_ols.py:216: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  b = (p + 2*n) * (q + 2*n) / 2 / (2*n + 1) / (n - 1)\n",
      "/home/ueay/bachelorarbeit-projekt/env/lib/python3.12/site-packages/statsmodels/multivariate/multivariate_ols.py:216: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  b = (p + 2*n) * (q + 2*n) / 2 / (2*n + 1) / (n - 1)\n",
      "/home/ueay/bachelorarbeit-projekt/env/lib/python3.12/site-packages/statsmodels/multivariate/multivariate_ols.py:216: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  b = (p + 2*n) * (q + 2*n) / 2 / (2*n + 1) / (n - 1)\n",
      "/home/ueay/bachelorarbeit-projekt/env/lib/python3.12/site-packages/statsmodels/multivariate/multivariate_ols.py:216: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  b = (p + 2*n) * (q + 2*n) / 2 / (2*n + 1) / (n - 1)\n",
      "/home/ueay/bachelorarbeit-projekt/env/lib/python3.12/site-packages/statsmodels/multivariate/multivariate_ols.py:216: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  b = (p + 2*n) * (q + 2*n) / 2 / (2*n + 1) / (n - 1)\n",
      "/home/ueay/bachelorarbeit-projekt/env/lib/python3.12/site-packages/statsmodels/multivariate/multivariate_ols.py:216: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  b = (p + 2*n) * (q + 2*n) / 2 / (2*n + 1) / (n - 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Effect</th>\n",
       "      <th>Test</th>\n",
       "      <th>Value</th>\n",
       "      <th>F</th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IsolationForest</td>\n",
       "      <td>C(seq_len)</td>\n",
       "      <td>Wilks' lambda</td>\n",
       "      <td>0.002</td>\n",
       "      <td>32.981</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IsolationForest</td>\n",
       "      <td>C(seq_len)</td>\n",
       "      <td>Pillai's trace</td>\n",
       "      <td>1.529</td>\n",
       "      <td>5.403</td>\n",
       "      <td>0.0099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IsolationForest</td>\n",
       "      <td>C(seq_len)</td>\n",
       "      <td>Hotelling-Lawley trace</td>\n",
       "      <td>310.272</td>\n",
       "      <td>206.848</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IsolationForest</td>\n",
       "      <td>C(seq_len)</td>\n",
       "      <td>Roy's greatest root</td>\n",
       "      <td>309.137</td>\n",
       "      <td>515.228</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OCSVM</td>\n",
       "      <td>C(seq_len)</td>\n",
       "      <td>Wilks' lambda</td>\n",
       "      <td>0.000</td>\n",
       "      <td>72.133</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>OCSVM</td>\n",
       "      <td>C(seq_len)</td>\n",
       "      <td>Pillai's trace</td>\n",
       "      <td>1.479</td>\n",
       "      <td>4.729</td>\n",
       "      <td>0.0155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>OCSVM</td>\n",
       "      <td>C(seq_len)</td>\n",
       "      <td>Hotelling-Lawley trace</td>\n",
       "      <td>1580.386</td>\n",
       "      <td>1053.591</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>OCSVM</td>\n",
       "      <td>C(seq_len)</td>\n",
       "      <td>Roy's greatest root</td>\n",
       "      <td>1579.465</td>\n",
       "      <td>2632.441</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DBSCAN</td>\n",
       "      <td>C(seq_len)</td>\n",
       "      <td>Wilks' lambda</td>\n",
       "      <td>0.000</td>\n",
       "      <td>211.409</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DBSCAN</td>\n",
       "      <td>C(seq_len)</td>\n",
       "      <td>Pillai's trace</td>\n",
       "      <td>1.970</td>\n",
       "      <td>109.829</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DBSCAN</td>\n",
       "      <td>C(seq_len)</td>\n",
       "      <td>Hotelling-Lawley trace</td>\n",
       "      <td>759.117</td>\n",
       "      <td>506.078</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DBSCAN</td>\n",
       "      <td>C(seq_len)</td>\n",
       "      <td>Roy's greatest root</td>\n",
       "      <td>725.053</td>\n",
       "      <td>1208.422</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Algorithm      Effect                    Test     Value         F  \\\n",
       "0   IsolationForest  C(seq_len)           Wilks' lambda     0.002    32.981   \n",
       "1   IsolationForest  C(seq_len)          Pillai's trace     1.529     5.403   \n",
       "2   IsolationForest  C(seq_len)  Hotelling-Lawley trace   310.272   206.848   \n",
       "3   IsolationForest  C(seq_len)     Roy's greatest root   309.137   515.228   \n",
       "4             OCSVM  C(seq_len)           Wilks' lambda     0.000    72.133   \n",
       "5             OCSVM  C(seq_len)          Pillai's trace     1.479     4.729   \n",
       "6             OCSVM  C(seq_len)  Hotelling-Lawley trace  1580.386  1053.591   \n",
       "7             OCSVM  C(seq_len)     Roy's greatest root  1579.465  2632.441   \n",
       "8            DBSCAN  C(seq_len)           Wilks' lambda     0.000   211.409   \n",
       "9            DBSCAN  C(seq_len)          Pillai's trace     1.970   109.829   \n",
       "10           DBSCAN  C(seq_len)  Hotelling-Lawley trace   759.117   506.078   \n",
       "11           DBSCAN  C(seq_len)     Roy's greatest root   725.053  1208.422   \n",
       "\n",
       "         p  \n",
       "0   0.0000  \n",
       "1   0.0099  \n",
       "2   0.0001  \n",
       "3   0.0000  \n",
       "4   0.0000  \n",
       "5   0.0155  \n",
       "6   0.0000  \n",
       "7   0.0000  \n",
       "8   0.0000  \n",
       "9   0.0000  \n",
       "10  0.0000  \n",
       "11  0.0000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.multivariate.manova import MANOVA\n",
    "\n",
    "# Daten für alle drei Algorithmen\n",
    "data = {\n",
    "    'algorithm': ['IsolationForest']*9 + ['OCSVM']*9 + ['DBSCAN']*9,\n",
    "    'seq_len': [10]*3 + [25]*3 + [50]*3 + [10]*3 + [25]*3 + [50]*3 + [10]*3 + [25]*3 + [50]*3,\n",
    "    'f1': [\n",
    "        0.8534,0.8831,0.8583, 0.7512,0.7647,0.7651, 0.5944,0.5410,0.6009,\n",
    "        0.8655,0.8831,0.8560, 0.7548,0.7651,0.7656, 0.6014,0.5901,0.6009,\n",
    "        0.2585,0.2222,0.3590, 0.0846,0.0846,0.0920, 0.0506,0.0506,0.0506\n",
    "    ],\n",
    "    'mcc': [\n",
    "        0.8553,0.8862,0.8574, 0.7574,0.7771,0.7747, 0.6069,0.5044,0.6030,\n",
    "        0.8654,0.8862,0.8542, 0.7622,0.7747,0.7725, 0.5692,0.5570,0.6030,\n",
    "        0.3817,0.3502,0.4637, 0.2059,0.2059,0.2150, 0.1553,0.1553,0.1553\n",
    "    ],\n",
    "    'balanced_acc': [\n",
    "        0.8863,0.8984,0.9016, 0.8142,0.8130,0.8167, 0.7236,0.7568,0.7330,\n",
    "        0.9017,0.8984,0.9053, 0.8144,0.8167,0.8205, 0.7966,0.7951,0.7330,\n",
    "        0.5742,0.5625,0.6094, 0.5221,0.5221,0.5241, 0.5130,0.5130,0.5130\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "def manova_to_df(manova_results, algorithm_name):\n",
    "    results = manova_results.mv_test().results\n",
    "    rows = []\n",
    "    for effect, val in results.items():\n",
    "        if effect == 'Intercept':\n",
    "            continue\n",
    "        stats = val['stat']\n",
    "        for test_name in ['Wilks\\' lambda', 'Pillai\\'s trace', 'Hotelling-Lawley trace', 'Roy\\'s greatest root']:\n",
    "            row = {\n",
    "                'Algorithm': algorithm_name,\n",
    "                'Effect': effect,\n",
    "                'Test': test_name,\n",
    "                'Value': round(stats.loc[test_name, 'Value'], 3),\n",
    "                'F': round(stats.loc[test_name, 'F Value'], 3),\n",
    "                'p': round(stats.loc[test_name, 'Pr > F'], 4)\n",
    "            }\n",
    "            rows.append(row)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# Isolation Forest\n",
    "manova_if = MANOVA.from_formula('f1 + mcc + balanced_acc ~ C(seq_len)', data=df[df.algorithm=='IsolationForest'])\n",
    "df_if = manova_to_df(manova_if, 'IsolationForest')\n",
    "\n",
    "# OCSVM\n",
    "manova_ocsvm = MANOVA.from_formula('f1 + mcc + balanced_acc ~ C(seq_len)', data=df[df.algorithm=='OCSVM'])\n",
    "df_ocsvm = manova_to_df(manova_ocsvm, 'OCSVM')\n",
    "\n",
    "# DBSCAN\n",
    "manova_dbscan = MANOVA.from_formula('f1 + mcc + balanced_acc ~ C(seq_len)', data=df[df.algorithm=='DBSCAN'])\n",
    "df_dbscan = manova_to_df(manova_dbscan, 'DBSCAN')\n",
    "\n",
    "# Alles zusammen\n",
    "df_all = pd.concat([df_if, df_ocsvm, df_dbscan], ignore_index=True)\n",
    "df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9f66d3",
   "metadata": {},
   "source": [
    "## Cross Validation Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85056e1",
   "metadata": {},
   "source": [
    "### Für LSTM-AE und IF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a00c081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'true_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     21\u001b[39m y_test_seq_if = np.array([y_test_full[i + seq_length- \u001b[32m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(val_anomaly_if))])\n\u001b[32m     22\u001b[39m true_labels_if = y_test_seq_if.astype(\u001b[38;5;28mint\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m precision, recall, f1, _ = precision_recall_fscore_support(\u001b[43mtrue_labels\u001b[49m, y_pred, average=\u001b[33m'\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     25\u001b[39m roc_auc = roc_auc_score(true_labels, iforest.decision_function(test_errors.reshape(-\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m)) * -\u001b[32m1\u001b[39m)\n\u001b[32m     27\u001b[39m all_precisions.append(precision)\n",
      "\u001b[31mNameError\u001b[39m: name 'true_labels' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import numpy as np\n",
    "\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "all_precisions, all_recalls, all_f1s, all_roc_aucs = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X_test_full)):\n",
    "    print(f\"Fold {fold + 1}/{n_splits}\")\n",
    "\n",
    "    model.fit(train_gen, validation_data=val_gen, epochs=50, callbacks=[early_stop], verbose=0)\n",
    "\n",
    "    iforest = IsolationForest()\n",
    "    iforest.fit(train_errors.reshape(-1, 1))\n",
    "\n",
    "    test_preds_if = iforest.predict(test_errors.reshape(-1, 1))\n",
    "    val_anomaly_if = (test_preds_if == -1).astype(int)\n",
    "\n",
    "    y_test_seq_if = np.array([y_test_full[i + seq_length- 1] for i in range(len(val_anomaly_if))])\n",
    "    true_labels_if = y_test_seq_if.astype(int)\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, y_pred, average='binary')\n",
    "    roc_auc = roc_auc_score(true_labels, iforest.decision_function(test_errors.reshape(-1, 1)) * -1)\n",
    "\n",
    "    all_precisions.append(precision)\n",
    "    all_recalls.append(recall)\n",
    "    all_f1s.append(f1)\n",
    "    all_roc_aucs.append(roc_auc)\n",
    "\n",
    "    print(f\"Mean Precision: {np.mean(all_precisions):.3f} ± {np.std(all_precisions):.3f}\")\n",
    "    print(f\"Mean Recall: {np.mean(all_recalls):.3f} ± {np.std(all_recalls):.3f}\")\n",
    "    print(f\"Mean F1-Score: {np.mean(all_f1s):.3f} ± {np.std(all_f1s):.3f}\")\n",
    "    print(f\"Mean ROC-AUC: {np.mean(all_roc_aucs):.3f} ± {np.std(all_roc_aucs):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe55044",
   "metadata": {},
   "source": [
    "### Für LSTM-AE und OCSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d53ac91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import numpy as np\n",
    "\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "all_precisions, all_recalls, all_f1s, all_roc_aucs = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X_test_full)):\n",
    "    print(f\"Fold {fold + 1}/{n_splits}\")\n",
    "\n",
    "    model.fit(train_gen, validation_data=val_gen, epochs=50, callbacks=[early_stop], verbose=0)\n",
    "    ocsvm = OneClassSVM(nu=0.005, gamma=50)\n",
    "    ocsvm.fit(train_errors.reshape(-1, 1))\n",
    "\n",
    "    test_preds_ocsvm = ocsvm.predict(test_errors.reshape(-1, 1))\n",
    "    test_anomaly_ocsvm = (test_preds_ocsvm == -1).astype(int)\n",
    "\n",
    "    y_test_seq_ocsvm = np.array([y_test_full[i + seq_length - 1] for i in range(len(test_anomaly_ocsvm))])\n",
    "    true_labels_ocsvm = y_test_seq.astype(int)\n",
    "\n",
    "    report_ocsvm = classification_report(true_labels_ocsvm, test_anomaly_ocsvm)\n",
    "\n",
    "    all_precisions.append(precision)\n",
    "    all_recalls.append(recall)\n",
    "    all_f1s.append(f1)\n",
    "    all_roc_aucs.append(roc_auc)\n",
    "\n",
    "    print(f\"Mean Precision: {np.mean(all_precisions):.3f} ± {np.std(all_precisions):.3f}\")\n",
    "    print(f\"Mean Recall: {np.mean(all_recalls):.3f} ± {np.std(all_recalls):.3f}\")\n",
    "    print(f\"Mean F1-Score: {np.mean(all_f1s):.3f} ± {np.std(all_f1s):.3f}\")\n",
    "    print(f\"Mean ROC-AUC: {np.mean(all_roc_aucs):.3f} ± {np.std(all_roc_aucs):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4e07bf",
   "metadata": {},
   "source": [
    "### Für LSTM-AE und DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdb81bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import numpy as np\n",
    "\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "all_precisions, all_recalls, all_f1s, all_roc_aucs = [], [], [], []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X_test_full)):\n",
    "    print(f\"Fold {fold + 1}/{n_splits}\")\n",
    "\n",
    "    model.fit(train_gen, validation_data=val_gen, epochs=50, callbacks=[early_stop], verbose=0)\n",
    "    dbscan = DBSCAN(eps = 0.05, min_samples = 40)\n",
    "\n",
    "    dbscan_labels = dbscan.fit_predict(test_errors.reshape(-1, 1))\n",
    "    dbscan_anomaly = (dbscan_labels == -1).astype(int)\n",
    "\n",
    "    y_test_seq_dbscan = np.array([y_test_full[i + seq_length - 1] for i in range(len(dbscan_anomaly))])\n",
    "    true_labels_dbscan = y_test_seq_dbscan.astype(int)\n",
    "    \n",
    "    all_precisions.append(precision)\n",
    "    all_recalls.append(recall)\n",
    "    all_f1s.append(f1)\n",
    "    all_roc_aucs.append(roc_auc)\n",
    "\n",
    "    print(f\"Mean Precision: {np.mean(all_precisions):.3f} ± {np.std(all_precisions):.3f}\")\n",
    "    print(f\"Mean Recall: {np.mean(all_recalls):.3f} ± {np.std(all_recalls):.3f}\")\n",
    "    print(f\"Mean F1-Score: {np.mean(all_f1s):.3f} ± {np.std(all_f1s):.3f}\")\n",
    "    print(f\"Mean ROC-AUC: {np.mean(all_roc_aucs):.3f} ± {np.std(all_roc_aucs):.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
