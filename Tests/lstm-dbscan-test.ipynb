{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb6abdb9",
   "metadata": {},
   "source": [
    "# Ein Hybridmodell mit LSTM-AE, DBSCAN und IF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8183868f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 10:44:00.760694: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-17 10:44:00.762471: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-17 10:44:00.794965: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-17 10:44:00.795643: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-17 10:44:01.301814: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.metrics import (\n",
    "    adjusted_rand_score,\n",
    "    homogeneity_score,\n",
    "    fowlkes_mallows_score\n",
    ")\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "import logging\n",
    "from tensorflow.keras.layers import TimeDistributed, Dense, LSTM, Dropout, LayerNormalization, Input, Add, Bidirectional, RepeatVector\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.layers import LSTM, Dropout, LayerNormalization, Add, TimeDistributed, Dense\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b37113",
   "metadata": {},
   "source": [
    "## 1. Vorbereitung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c0fe8b",
   "metadata": {},
   "source": [
    "#### Cuda auslassen, weil DGX verwendet wird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8427ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185398f1",
   "metadata": {},
   "source": [
    "#### Daten laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5a6c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         timestamp    log_type   userId       ipAddress  \\\n",
      "0 2025-06-11 19:34:10.768151+02:00  user_event  user_27  99.214.127.119   \n",
      "1 2025-06-11 19:34:10.769529+02:00  user_event  user_27   18.224.80.186   \n",
      "2 2025-06-11 19:34:10.769972+02:00  user_event  user_14  68.175.210.188   \n",
      "3 2025-06-11 19:34:10.770055+02:00  user_event  user_32   34.191.216.62   \n",
      "4 2025-06-11 19:34:10.770289+02:00  user_event  user_32   44.161.216.50   \n",
      "\n",
      "                         roles    realmId      clientId      authMethod  \\\n",
      "0                       [user]   frontend  frontend-app            saml   \n",
      "1                     [member]   internal  frontend-app  openid-connect   \n",
      "2  [viewer, uma_authorization]  app-users  frontend-app  openid-connect   \n",
      "3               [user, member]   frontend  frontend-app  openid-connect   \n",
      "4                       [user]   internal  frontend-app            saml   \n",
      "\n",
      "  authType                                            details  \\\n",
      "0     code  {'connection': 'saml', 'user_agent': 'Mozilla/...   \n",
      "1     code  {'connection': 'saml', 'user_agent': 'Mozilla/...   \n",
      "2     code  {'connection': 'saml', 'user_agent': 'Mozilla/...   \n",
      "3     code  {'connection': 'default', 'user_agent': 'Mozil...   \n",
      "4     code  {'connection': 'default', 'user_agent': 'Mozil...   \n",
      "\n",
      "                 user_agent           type  label operation adminId resource  \\\n",
      "0  Mozilla/5.0 (compatible)          LOGIN      0       NaN     NaN      NaN   \n",
      "1  Mozilla/5.0 (compatible)  TOKEN_REFRESH      0       NaN     NaN      NaN   \n",
      "2  Mozilla/5.0 (compatible)          LOGIN      0       NaN     NaN      NaN   \n",
      "3  Mozilla/5.0 (compatible)          LOGIN      0       NaN     NaN      NaN   \n",
      "4  Mozilla/5.0 (compatible)  TOKEN_REFRESH      0       NaN     NaN      NaN   \n",
      "\n",
      "  resource_path  \n",
      "0           NaN  \n",
      "1           NaN  \n",
      "2           NaN  \n",
      "3           NaN  \n",
      "4           NaN  \n"
     ]
    }
   ],
   "source": [
    "data_train = pd.read_json(\"train_logs.json\", lines=False)\n",
    "data_test = pd.read_json(\"test_logs.json\", lines=False)\n",
    "data_val = pd.read_json(\"val_logs.json\", lines=False)\n",
    "print(data_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1132d010",
   "metadata": {},
   "source": [
    "#### NaN-Werte bereinigen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321cb5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full = pd.DataFrame(data_train)\n",
    "X_test_full = pd.DataFrame(data_test)\n",
    "X_val_full = pd.DataFrame(data_val)\n",
    "\n",
    "X_train_full = X_train_full.apply(lambda col: pd.to_numeric(col, errors='coerce')).fillna(0)\n",
    "X_test_full = X_test_full.apply(lambda col: pd.to_numeric(col, errors='coerce')).fillna(0)\n",
    "X_val_full = X_val_full.apply(lambda col: pd.to_numeric(col, errors='coerce')).fillna(0)\n",
    "\n",
    "y_test_full = data_test[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d90c1e",
   "metadata": {},
   "source": [
    "#### Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8dd938",
   "metadata": {},
   "outputs": [],
   "source": [
    "logfile = open(\"output_log.txt\", \"w\")\n",
    "logging.basicConfig(stream=logfile, level=logging.INFO)\n",
    "\n",
    "sys.stdout = logfile\n",
    "sys.stderr = logfile\n",
    "\n",
    "print(\"Das ist eine Print-Ausgabe.\")\n",
    "logging.info(\"Das ist eine Log-Nachricht.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b904244",
   "metadata": {},
   "source": [
    "#### Automatisch alles in Numerische oder Kategorische Daten einteilen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaa7cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_encode_features(logs, one_hot_numeric=False, \n",
    "                         label_encoders=None, onehot_encoders=None, fit=True):\n",
    "    if logs is None or len(logs) == 0:\n",
    "        return [], {}, {}\n",
    "\n",
    "    if hasattr(logs, \"to_dict\"):\n",
    "        logs = logs.to_dict(orient='records')\n",
    "\n",
    "    if label_encoders is None:\n",
    "        label_encoders = {}\n",
    "    if onehot_encoders is None:\n",
    "        onehot_encoders = {}\n",
    "\n",
    "    sample = logs[0]\n",
    "    all_keys = sample.keys()\n",
    "    encoded_logs = []\n",
    "\n",
    "    for log in logs:\n",
    "        encoded = {}\n",
    "        for key in all_keys:\n",
    "            val = log.get(key)\n",
    "\n",
    "            if val is None:\n",
    "                continue\n",
    "\n",
    "            if isinstance(val, (int, float)) and not isinstance(val, bool):\n",
    "                if one_hot_numeric:\n",
    "                    if key not in onehot_encoders and fit:\n",
    "                        encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "                        values = np.array([[l.get(key)] for l in logs if l.get(key) is not None])\n",
    "                        encoder.fit(values)\n",
    "                        onehot_encoders[key] = encoder\n",
    "\n",
    "                    if key in onehot_encoders:\n",
    "                        enc = onehot_encoders[key].transform([[val]])[0]\n",
    "                        for i, v in enumerate(enc):\n",
    "                            encoded[f\"{key}_{i}\"] = v\n",
    "                else:\n",
    "                    encoded[key] = val\n",
    "\n",
    "            elif isinstance(val, str):\n",
    "                if key not in label_encoders and fit:\n",
    "                    le = LabelEncoder()\n",
    "                    values = [l.get(key) for l in logs if l.get(key) is not None]\n",
    "                    le.fit(values)\n",
    "                    label_encoders[key] = le\n",
    "\n",
    "                if key in label_encoders:\n",
    "                    encoded[key] = label_encoders[key].transform([val])[0]\n",
    "\n",
    "            elif isinstance(val, list):\n",
    "                for i, item in enumerate(val):\n",
    "                    label = f\"{key}_{i}\"\n",
    "                    if label not in label_encoders and fit:\n",
    "                        le = LabelEncoder()\n",
    "                        values = [item for l in logs for item in l.get(key, [])]\n",
    "                        le.fit(values)\n",
    "                        label_encoders[label] = le\n",
    "\n",
    "                    if label in label_encoders:\n",
    "                        encoded[label] = label_encoders[label].transform([item])[0]\n",
    "        encoded_logs.append(encoded)\n",
    "\n",
    "    return encoded_logs, label_encoders, onehot_encoders\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3ff107",
   "metadata": {},
   "source": [
    "#### Werte aus vorheriger Funktion vereinigen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d0002f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dicts_to_feature_matrix(encoded_logs):\n",
    "    feature_names = sorted({key for d in encoded_logs for key in d.keys()})\n",
    "\n",
    "    X = np.zeros((len(encoded_logs), len(feature_names)), dtype=np.float32)\n",
    "\n",
    "    for i, d in enumerate(encoded_logs):\n",
    "        for j, feat in enumerate(feature_names):\n",
    "            if feat in d:\n",
    "                X[i, j] = d[feat]\n",
    "\n",
    "    return X, feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d825cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_train = X_train_full.to_dict(orient='records')\n",
    "logs_test = X_test_full.to_dict(orient='records')\n",
    "logs_val = X_val_full.to_dict(orient='records')\n",
    "\n",
    "encoded_logs, label_encoders, onehot_encoders = auto_encode_features(logs_train, \n",
    "                                                one_hot_numeric=False, fit=True)\n",
    "X_train, feature_names = dicts_to_feature_matrix(encoded_logs)\n",
    "\n",
    "encoded_test_logs, _, _ = auto_encode_features(logs_test, one_hot_numeric=False,\n",
    "                                               label_encoders=label_encoders, onehot_encoders=onehot_encoders, fit=False)\n",
    "X_test, _ = dicts_to_feature_matrix(encoded_test_logs)\n",
    "\n",
    "encoded_val_logs, _, _ = auto_encode_features(logs_val, one_hot_numeric=False,\n",
    "                                              label_encoders=label_encoders, onehot_encoders=onehot_encoders, fit=False)\n",
    "X_val, _ = dicts_to_feature_matrix(encoded_val_logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b55383",
   "metadata": {},
   "source": [
    "#### Skalierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3445ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Werte skalieren\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train_full.to_numpy()).astype(np.float32)\n",
    "X_test_scaled = scaler.transform(X_test_full.reindex(columns=X_train_full.columns, fill_value=0).to_numpy()).astype(np.float32)\n",
    "X_val_scaled = scaler.transform(X_val_full.reindex(columns=X_train_full.columns, fill_value=0).to_numpy()).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f8c906",
   "metadata": {},
   "source": [
    "#### PCA zur Dimensionsreduktion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe69c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=10)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "X_val_pca = pca.transform(X_val_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f955d4",
   "metadata": {},
   "source": [
    "### Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad52d0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 32\n",
    "batch_size = 128\n",
    "\n",
    "encoder_layers = [1024, 512, 256]\n",
    "decoder_layers = [256, 512, 1024]\n",
    "\n",
    "dropout_rate = 0.2\n",
    "\n",
    "timesteps = seq_length\n",
    "n_features = X_train_pca.shape[1]\n",
    "learning_rate = 0.0001\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31049ba2",
   "metadata": {},
   "source": [
    "### Sequenzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b87923e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generatoren bleiben gleich\n",
    "class SequenceToSequenceGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, data, seq_length, batch_size):\n",
    "        self.data = data\n",
    "        self.seq_length = seq_length\n",
    "        self.batch_size = batch_size\n",
    "        self.indices = np.arange(len(data) - seq_length)\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.indices) + self.batch_size - 1) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_idx = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        if len(batch_idx) == 0:\n",
    "            batch_idx = self.indices[-self.batch_size:]\n",
    "        X_batch = np.array([self.data[i:i + self.seq_length] for i in batch_idx])\n",
    "        return X_batch, X_batch\n",
    "\n",
    "train_gen = SequenceToSequenceGenerator(X_train_pca, seq_length, batch_size)\n",
    "val_gen = SequenceToSequenceGenerator(X_val_pca, seq_length, batch_size)\n",
    "test_gen = SequenceToSequenceGenerator(X_test_pca, seq_length, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33d7452",
   "metadata": {},
   "source": [
    "## 2. LSTM-AE implementieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8edbf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "inputs = Input(shape=(timesteps, n_features))\n",
    "x = inputs\n",
    "\n",
    "def residual_lstm_block(x, units, dropout_rate=0.2):\n",
    "    shortcut = x\n",
    "    x = LSTM(units, return_sequences=True)(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = LayerNormalization()(x)\n",
    "\n",
    "    print(\"Shape x:\", K.int_shape(x))\n",
    "    print(\"Shape shortcut:\", K.int_shape(shortcut))\n",
    "    \n",
    "    if K.int_shape(shortcut)[-1] != units:\n",
    "        shortcut = TimeDistributed(Dense(units))(shortcut)\n",
    "        print(\"Shortcut after Dense:\", K.int_shape(shortcut))\n",
    "    \n",
    "    x = Add()([x, shortcut])\n",
    "    return x\n",
    "\n",
    "inputs = Input(shape=(timesteps, n_features))\n",
    "x = inputs\n",
    "\n",
    "for units in encoder_layers:\n",
    "    x = residual_lstm_block(x, units, dropout_rate=dropout_rate)\n",
    "\n",
    "encoded = Bidirectional(LSTM(encoder_layers[-1]))(x)\n",
    "print(\"Encoded shape:\", K.int_shape(encoded))  # (None, units*2)\n",
    "\n",
    "decoded = RepeatVector(timesteps)(encoded)\n",
    "print(\"Decoded shape:\", K.int_shape(decoded))  # (None, timesteps, units*2)\n",
    "\n",
    "x = decoded\n",
    "for units in decoder_layers:\n",
    "    x = LSTM(units, return_sequences=True)(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = LayerNormalization()(x)\n",
    "    print(\"Decoder layer output shape:\", K.int_shape(x))\n",
    "\n",
    "outputs = TimeDistributed(Dense(n_features, activation='linear'))(x)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "model.compile(optimizer=Adam(learning_rate), loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b747efe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "model.fit(train_gen, validation_data=val_gen, epochs=100, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5ebaae",
   "metadata": {},
   "source": [
    "### Umwandlung der Daten für nächste Modelle: Rekonstruktionsfehler berechnen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ede0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reconstruction_errors(gen, model):\n",
    "    errors = []\n",
    "    for i in range(len(gen)):\n",
    "        X_batch, _ = gen[i]\n",
    "        pred = model.predict(X_batch, verbose=0)\n",
    "        batch_errors = np.mean(np.square(X_batch - pred), axis=(1, 2))\n",
    "        errors.extend(batch_errors)\n",
    "    return np.array(errors)\n",
    "\n",
    "train_errors = get_reconstruction_errors(train_gen, model)\n",
    "reconstruction_errors = get_reconstruction_errors(test_gen, model)\n",
    "threshold = np.percentile(train_errors, 75)\n",
    "\n",
    "y_test_seq = np.array([y_test_full[i + seq_length - 1] for i in range(len(reconstruction_errors))])\n",
    "true_labels = y_test_seq.astype(int)\n",
    "fpr, tpr, thresholds = roc_curve(true_labels, reconstruction_errors)\n",
    "optimal_idx = (tpr - fpr).argmax()\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "y_pred = (reconstruction_errors > optimal_threshold).astype(int)\n",
    "\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(true_labels, y_pred, average='binary')\n",
    "roc_auc = roc_auc_score(true_labels, reconstruction_errors)\n",
    "logging.info(f\"Precision: {precision:.3f}, Recall: {recall:.3f}, F1-Score: {f1:.3f}, ROC-AUC: {roc_auc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00451659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder-Model bauen\n",
    "encoder = tf.keras.Model(inputs, encoded)\n",
    "\n",
    "# Batchweise encodieren, um RAM zu sparen\n",
    "X_encoded_batches = []\n",
    "for i in range(len(test_gen)):\n",
    "    X_batch, _ = test_gen[i]\n",
    "    encoded_batch = encoder.predict(X_batch, batch_size=len(X_batch), verbose=0)\n",
    "    X_encoded_batches.append(encoded_batch)\n",
    "X_encoded_new = np.vstack(X_encoded_batches)\n",
    "\n",
    "scaler_enc = StandardScaler()\n",
    "X_encoded_scaled = scaler_enc.fit_transform(X_encoded_new)\n",
    "X_encoded_scaled = X_encoded_scaled[-len(reconstruction_errors):]\n",
    "\n",
    "scaler_err = StandardScaler()\n",
    "reconstruction_errors_reshaped = reconstruction_errors.reshape(-1, 1)\n",
    "reconstruction_errors_scaled = scaler_err.fit_transform(reconstruction_errors_reshaped)\n",
    "hybrid_features = np.hstack((X_encoded_scaled, reconstruction_errors_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4288f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    hybrid_features,\n",
    "    true_labels,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=true_labels\n",
    ")\n",
    "\n",
    "# Dann: 12.5 % von 80 % ergibt 10 % des gesamten Datensatzes für Validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp,\n",
    "    y_temp,\n",
    "    test_size=0.125,  # 0.125 * 0.8 ≈ 0.10 vom Gesamtdatensatz\n",
    "    random_state=42,\n",
    "    stratify=y_temp\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1734c09",
   "metadata": {},
   "source": [
    "# Modell 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2c9f11",
   "metadata": {},
   "source": [
    "## Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c7b6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainiere nur auf Trainingsdaten\n",
    "iforest = IsolationForest(random_state=42)\n",
    "#iforest.fit(X_train)\n",
    "\n",
    "# Vorhersage auf VALIDIERUNGSDATEN\n",
    "val_preds = iforest.fit_predict(X_val)\n",
    "val_anomaly = (val_preds == -1).astype(int)\n",
    "\n",
    "report_iforest = classification_report(y_val, val_anomaly)\n",
    "logging.info(\"Isolation Forest - Validation Report:\\n\" + report_iforest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fa46b4",
   "metadata": {},
   "source": [
    "### IF MCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec9af7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcc = matthews_corrcoef(y_val, val_anomaly)\n",
    "logging.info(\"Matthews Correlation Coefficient: %f\", mcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c30aad",
   "metadata": {},
   "source": [
    "### IF Balanced Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c822d8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_acc = balanced_accuracy_score(y_val, val_anomaly)\n",
    "logging.info(\"Balanced Accuracy: %f\", balanced_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e136e11a",
   "metadata": {},
   "source": [
    "### IF AUC-Kurven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e29c7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Entscheidungsscores holen (höher = normal → invertieren für Anomalie)\n",
    "val_scores = -iforest.decision_function(X_val)\n",
    "\n",
    "# ROC-Kurve und AUC\n",
    "fpr, tpr, _ = roc_curve(y_val, val_scores)\n",
    "roc_auc = roc_auc_score(y_val, val_scores)\n",
    "\n",
    "# PR-Kurve und Average Precision\n",
    "precision, recall, _ = precision_recall_curve(y_val, val_scores)\n",
    "pr_auc = average_precision_score(y_val, val_scores)\n",
    "\n",
    "# Plotten\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# ROC\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.3f}\")\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve (Validation)\")\n",
    "plt.legend()\n",
    "\n",
    "# PR\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(recall, precision, label=f\"AP = {pr_auc:.3f}\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve (Validation)\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c707ea",
   "metadata": {},
   "source": [
    "### IF: Anomaly Scores berechnen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add85360",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = iforest.decision_function(hybrid_features)\n",
    "print(\"Scores:\", scores[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142607f1",
   "metadata": {},
   "source": [
    "# Modell 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c53e25c",
   "metadata": {},
   "source": [
    "## One-Class SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9085760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "ocsvm = OneClassSVM(kernel=\"rbf\", gamma='auto', nu=0.05)  # nu ~ erwarteter Anteil Anomalien\n",
    "#ocsvm.fit(X_train)\n",
    "\n",
    "val_preds = ocsvm.fit_predict(X_val)\n",
    "val_anomaly = (val_preds == -1).astype(int)\n",
    "\n",
    "report_ocsvm = classification_report(y_val, val_anomaly)\n",
    "logging.info(\"One-Class SVM - Validation Report:\\n\" + report_ocsvm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296736bf",
   "metadata": {},
   "source": [
    "### OCSVM MCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807a8958",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcc = matthews_corrcoef(y_val, val_anomaly)\n",
    "logging.info(\"Matthews Correlation Coefficient: %f\", mcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8df4624",
   "metadata": {},
   "source": [
    "### OCSVM Balanced Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f42ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_acc = balanced_accuracy_score(y_val, val_anomaly)\n",
    "logging.info(\"Balanced Accuracy: %f\", balanced_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80340a9",
   "metadata": {},
   "source": [
    "### OCSVM AUC-Kurven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8b1fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Anomalie-Scores holen (höher = normal, deshalb invertieren)\n",
    "val_scores = -ocsvm.decision_function(X_val)\n",
    "\n",
    "# ROC-Kurve und AUC\n",
    "fpr, tpr, _ = roc_curve(y_val, val_scores)\n",
    "roc_auc = roc_auc_score(y_val, val_scores)\n",
    "\n",
    "# Precision-Recall-Kurve und Average Precision\n",
    "precision, recall, _ = precision_recall_curve(y_val, val_scores)\n",
    "pr_auc = average_precision_score(y_val, val_scores)\n",
    "\n",
    "# Plotten\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# ROC Curve\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.3f}\")\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve (Validation)\")\n",
    "plt.legend()\n",
    "\n",
    "# PR Curve\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(recall, precision, label=f\"AP = {pr_auc:.3f}\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve (Validation)\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c764e2",
   "metadata": {},
   "source": [
    "### OCSVM: Anomaly-Scores berechnen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba740028",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_ocsvm = ocsvm.decision_function(hybrid_features)\n",
    "print(\"OCSVM Scores:\", scores_ocsvm[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbec00d7",
   "metadata": {},
   "source": [
    "# Modell 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d99cac7",
   "metadata": {},
   "source": [
    "## DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97aea0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps=0.5, min_samples=5)  \n",
    "dbscan_labels = dbscan.fit_predict(X_test)\n",
    "dbscan_anomaly = (dbscan_labels == -1).astype(int)\n",
    "logging.info(\"\\n\" + classification_report(y_test, dbscan_anomaly))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b549c490",
   "metadata": {},
   "source": [
    "### DBSCAN Werte: ARI, HOMO, FMI, Noise Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d0fed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ari  = adjusted_rand_score(y_test, dbscan_anomaly)\n",
    "homo = homogeneity_score(y_test, dbscan_anomaly)\n",
    "fmi  = fowlkes_mallows_score(y_test, dbscan_anomaly)\n",
    "noise_ratio = np.sum(dbscan_labels == -1) / len(dbscan_labels)\n",
    "\n",
    "logging.info(f\"Adjusted Rand Index (ARI):     {ari:.4f}\")\n",
    "logging.info(f\"Homogeneity:                   {homo:.4f}\")\n",
    "logging.info(f\"Fowlkes-Mallows Index (FMI):   {fmi:.4f}\")\n",
    "logging.info(f\"Noise Ratio: {noise_ratio:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab11cd46",
   "metadata": {},
   "source": [
    "### DBSCAN MCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5a46a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcc = matthews_corrcoef(y_test, dbscan_anomaly)\n",
    "logging.info(\"Matthews Correlation Coefficient: %f\", mcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5811f342",
   "metadata": {},
   "source": [
    "### DBSCAN Balanced Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a53ffc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_acc = balanced_accuracy_score(y_test, dbscan_anomaly)\n",
    "logging.info(\"Balanced Accuracy: %f\", balanced_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2569e8b7",
   "metadata": {},
   "source": [
    "### DBSCAN AUC-Kurven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc51f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Nutze die binäre Anomalie-Maske als \"Score\" (0 = normal, 1 = Anomalie)\n",
    "# → das ergibt eine einzelne Schwelle (wenig Aussagekraft, aber technisch machbar)\n",
    "scores = dbscan_anomaly  # 0 oder 1\n",
    "\n",
    "# ROC\n",
    "fpr, tpr, _ = roc_curve(y_test, scores)\n",
    "roc_auc = roc_auc_score(y_test, scores)\n",
    "\n",
    "# Precision-Recall\n",
    "precision, recall, _ = precision_recall_curve(y_test, scores)\n",
    "pr_auc = average_precision_score(y_test, scores)\n",
    "\n",
    "# Plotten\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# ROC\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.3f}\")\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve (DBSCAN)\")\n",
    "plt.legend()\n",
    "\n",
    "# PR\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(recall, precision, label=f\"AP = {pr_auc:.3f}\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve (DBSCAN)\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
