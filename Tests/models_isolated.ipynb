{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4be1983",
   "metadata": {},
   "source": [
    "# Test mit den Modellen einzeln"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d6c846",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7525914f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve, average_precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5074318",
   "metadata": {},
   "source": [
    "### Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd950b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "logfile_two = open(\"output_log_isolated.txt\", \"w\")\n",
    "\n",
    "sys.stdout = logfile_two\n",
    "sys.stderr = logfile_two\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    stream=logfile_two,\n",
    "    force=True  # falls schon vorher etwas konfiguriert war\n",
    ")\n",
    "\n",
    "print(\"Das ist eine Print-Ausgabe.\")\n",
    "logging.info(\"Das ist eine Log-Nachricht.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cbcc13",
   "metadata": {},
   "source": [
    "### Logs laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df309d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_json(\"train_logs_isolated.json\", lines=False)\n",
    "data_test = pd.read_json(\"test_logs.json\", lines=False)\n",
    "data_val = pd.read_json(\"val_logs.json\", lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3735a81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full = pd.DataFrame(data_train)\n",
    "X_test_full = pd.DataFrame(data_test)\n",
    "X_val_full = pd.DataFrame(data_val)\n",
    "y_test_full = data_test[\"label\"]\n",
    "y_val_full = data_val[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5763cc1",
   "metadata": {},
   "source": [
    "### Daten in numerisch/kategorisch unterteilen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e5c4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "def is_missing(val):\n",
    "    return val is None or (isinstance(val, float) and np.isnan(val))\n",
    "\n",
    "def auto_encode_features(logs, one_hot_numeric=False, \n",
    "                         label_encoders=None, onehot_encoders=None, fit=True):\n",
    "    if logs is None or len(logs) == 0:\n",
    "        return [], {}, {}\n",
    "\n",
    "    if hasattr(logs, \"to_dict\"):\n",
    "        logs = logs.to_dict(orient='records')\n",
    "\n",
    "    if label_encoders is None:\n",
    "        label_encoders = {}\n",
    "    if onehot_encoders is None:\n",
    "        onehot_encoders = {}\n",
    "\n",
    "    sample = logs[0]\n",
    "    all_keys = sample.keys()\n",
    "    encoded_logs = []\n",
    "\n",
    "    for log in logs:\n",
    "        encoded = {}\n",
    "        for key in all_keys:\n",
    "            val = log.get(key)\n",
    "\n",
    "            # Fehlt etwas? → Speziell ersetzen\n",
    "            if is_missing(val):\n",
    "                val = \"__MISSING__\"\n",
    "\n",
    "            # Numerisch?\n",
    "            if isinstance(val, (int, float)) and not isinstance(val, bool):\n",
    "                if val == \"__MISSING__\":\n",
    "                    encoded[key] = -9999  # spezieller Platzhalter für fehlende Zahl\n",
    "                elif one_hot_numeric:\n",
    "                    if key not in onehot_encoders and fit:\n",
    "                        values = np.array([[l.get(key) if not is_missing(l.get(key)) else -9999]\n",
    "                                           for l in logs])\n",
    "                        encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "                        encoder.fit(values)\n",
    "                        onehot_encoders[key] = encoder\n",
    "\n",
    "                    if key in onehot_encoders:\n",
    "                        enc = onehot_encoders[key].transform([[val]])[0]\n",
    "                        for i, v in enumerate(enc):\n",
    "                            encoded[f\"{key}_{i}\"] = v\n",
    "                else:\n",
    "                    encoded[key] = val\n",
    "\n",
    "            # String (kategorisch)\n",
    "            elif isinstance(val, str):\n",
    "                if key not in label_encoders and fit:\n",
    "                    values = list(set(l.get(key) if not is_missing(l.get(key)) else \"__MISSING__\"\n",
    "                                      for l in logs))\n",
    "                    le = LabelEncoder()\n",
    "                    le.fit(values)\n",
    "                    label_encoders[key] = le\n",
    "\n",
    "                if key in label_encoders:\n",
    "                    le = label_encoders[key]\n",
    "                    if val in le.classes_:\n",
    "                        encoded[key] = le.transform([val])[0]\n",
    "                    else:\n",
    "                        encoded[key] = -1  # unbekannte Kategorie\n",
    "\n",
    "            # Listen\n",
    "            elif isinstance(val, list):\n",
    "                for i, item in enumerate(val):\n",
    "                    if is_missing(item):\n",
    "                        item = \"__MISSING__\"\n",
    "\n",
    "                    label = f\"{key}_{i}\"\n",
    "                    if label not in label_encoders and fit:\n",
    "                        values = list(set(itm if not is_missing(itm) else \"__MISSING__\"\n",
    "                                          for l in logs for itm in l.get(key, [])))\n",
    "                        le = LabelEncoder()\n",
    "                        le.fit(values)\n",
    "                        label_encoders[label] = le\n",
    "\n",
    "                    if label in label_encoders:\n",
    "                        le = label_encoders[label]\n",
    "                        if item in le.classes_:\n",
    "                            encoded[label] = le.transform([item])[0]\n",
    "                        else:\n",
    "                            encoded[label] = -1\n",
    "\n",
    "        encoded_logs.append(encoded)\n",
    "\n",
    "    return encoded_logs, label_encoders, onehot_encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd1846c",
   "metadata": {},
   "source": [
    "### Zusammenfügen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1234eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dicts_to_feature_matrix(encoded_logs):\n",
    "    feature_names = sorted({key for d in encoded_logs for key in d.keys()})\n",
    "\n",
    "    X = np.zeros((len(encoded_logs), len(feature_names)), dtype=np.float32)\n",
    "\n",
    "    for i, d in enumerate(encoded_logs):\n",
    "        for j, feat in enumerate(feature_names):\n",
    "            if feat in d:\n",
    "                X[i, j] = d[feat]\n",
    "\n",
    "    return X, feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ea765e",
   "metadata": {},
   "source": [
    "### Daten unterteilen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36292be",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_train = X_train_full.to_dict(orient='records')\n",
    "logs_test = X_test_full.to_dict(orient='records')\n",
    "logs_val = X_val_full.to_dict(orient='records')\n",
    "\n",
    "encoded_logs, label_encoders, onehot_encoders = auto_encode_features(\n",
    "    logs_train, one_hot_numeric=True, fit=True\n",
    ")\n",
    "X_train, feature_names = dicts_to_feature_matrix(encoded_logs)\n",
    "\n",
    "encoded_test_logs, _, _ = auto_encode_features(\n",
    "    logs_test, one_hot_numeric=True,\n",
    "    label_encoders=label_encoders, onehot_encoders=onehot_encoders, fit=False\n",
    ")\n",
    "X_test, _ = dicts_to_feature_matrix(encoded_test_logs)\n",
    "\n",
    "encoded_val_logs, _, _ = auto_encode_features(\n",
    "    logs_val, one_hot_numeric=True,\n",
    "    label_encoders=label_encoders, onehot_encoders=onehot_encoders, fit=False\n",
    ")\n",
    "X_val, _ = dicts_to_feature_matrix(encoded_val_logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7b87bb",
   "metadata": {},
   "source": [
    "### Skalieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3360231",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_val_scaled = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e73d9f",
   "metadata": {},
   "source": [
    "### Test mit IF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639622ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "iforest = IsolationForest()\n",
    "iforest.fit(X_train_scaled)\n",
    "\n",
    "test_scores = iforest.decision_function(X_test_scaled)\n",
    "test_preds = iforest.predict(X_test_scaled)\n",
    "y_test_pred = (test_preds == -1).astype(int)\n",
    "logging.info(\"Test Classification Report:\\n\" + classification_report(y_test_full, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e1bb5a",
   "metadata": {},
   "source": [
    "### Test IF MCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc97862",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcc = matthews_corrcoef(y_test_full, y_test_pred)\n",
    "logging.info(\"Matthews Correlation Coefficient: %f\", mcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b126e4c7",
   "metadata": {},
   "source": [
    "### Test IF Balanced Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb30df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_acc = balanced_accuracy_score(y_test_full, y_test_pred)\n",
    "logging.info(\"Balanced Accuracy: %f\", balanced_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5da02f",
   "metadata": {},
   "source": [
    "### Test IF AUC-Kurven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98cdc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anomaly Scores invertieren (höher = anomal)\n",
    "anomaly_scores = -test_scores\n",
    "\n",
    "# ROC-Kurve und AUC\n",
    "fpr, tpr, _ = roc_curve(y_test_full, anomaly_scores)\n",
    "roc_auc = roc_auc_score(y_test_full, anomaly_scores)\n",
    "\n",
    "# Precision-Recall-Kurve und Average Precision (PR AUC)\n",
    "precision, recall, _ = precision_recall_curve(y_test_full, anomaly_scores)\n",
    "pr_auc = average_precision_score(y_test_full, anomaly_scores)\n",
    "\n",
    "# Plot ROC Curve\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.3f}\")\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot Precision-Recall Curve\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(recall, precision, label=f\"AP = {pr_auc:.3f}\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe99bb0e",
   "metadata": {},
   "source": [
    "### Test DBSCAN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7af3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps = 0.05, min_samples = 40)\n",
    "dbscan_labels_test = dbscan.fit_predict(X_test_scaled)\n",
    "dbscan_anomaly_test = (dbscan_labels_test == -1).astype(int)\n",
    "logging.info(\"Test Classification Report:\\n\" + classification_report(y_test_full, dbscan_anomaly_test, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54975d05",
   "metadata": {},
   "source": [
    "### Test DBSCAN MCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d435804",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcc = matthews_corrcoef(y_test_full, dbscan_anomaly_test)\n",
    "logging.info(\"Matthews Correlation Coefficient: %f\", mcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0009ecb3",
   "metadata": {},
   "source": [
    "### Test DBSCAN Balanced Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa8f15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_acc = balanced_accuracy_score(y_test_full, dbscan_anomaly_test)\n",
    "logging.info(\"Balanced Accuracy: %f\", balanced_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af412a5",
   "metadata": {},
   "source": [
    "### Test DBSCAN AUC-Kurven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e305cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy-Scores: Anomalie = 1.0, Normal = 0.0 (nicht ideal!)\n",
    "anomaly_scores = (dbscan_labels_test == -1).astype(float)\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test_full, anomaly_scores)\n",
    "roc_auc = roc_auc_score(y_test_full, anomaly_scores)\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_test_full, anomaly_scores)\n",
    "pr_auc = average_precision_score(y_test_full, anomaly_scores)\n",
    "\n",
    "# Plotten\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.3f}\")\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(recall, precision, label=f\"AP = {pr_auc:.3f}\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5fc08b",
   "metadata": {},
   "source": [
    "### Test OCSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f8d7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ocsvm = OneClassSVM(nu=0.005, gamma=50)\n",
    "ocsvm.fit(X_train_scaled)\n",
    "\n",
    "y_pred_test = ocsvm.predict(X_test_scaled)\n",
    "anomaly_test = (y_pred_test == -1).astype(int)\n",
    "logging.info(\"Test Report:\\n\" + classification_report(y_test_full, anomaly_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e320b9d",
   "metadata": {},
   "source": [
    "### OCSVM MCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1128357",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcc = matthews_corrcoef(y_test_full, anomaly_test)\n",
    "logging.info(\"Matthews Correlation Coefficient: %f\", mcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bacbd7",
   "metadata": {},
   "source": [
    "### OCSVM Balanced Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3948d7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_acc = balanced_accuracy_score(y_test_full, anomaly_test)\n",
    "logging.info(\"Balanced Accuracy: %f\", balanced_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59789ad7",
   "metadata": {},
   "source": [
    "### OCSVM AUC-Kurven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f675ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score: Decision Function (negiert für \"mehr Anomalie = höherer Score\")\n",
    "scores = -ocsvm.decision_function(X_test_scaled)\n",
    "\n",
    "# ROC\n",
    "fpr, tpr, _ = roc_curve(y_test_full, scores)\n",
    "roc_auc = roc_auc_score(y_test_full, scores)\n",
    "\n",
    "# Precision-Recall\n",
    "precision, recall, _ = precision_recall_curve(y_test_full, scores)\n",
    "pr_auc = average_precision_score(y_test_full, scores)\n",
    "\n",
    "# Plotten\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# ROC\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.3f}\")\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# PR\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(recall, precision, label=f\"AP = {pr_auc:.3f}\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
